### YamlMime:RESTOperation
uid: management.azure.com.media.jobs.get
name: Get
service: Media Services
groupName: Jobs
apiVersion: 2021-11-01
summary: "Get Job  \nGets a Job."
consumes:
- application/json
produces:
- application/json
paths:
- content: GET https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Media/mediaServices/{accountName}/transforms/{transformName}/jobs/{jobName}?api-version=2021-11-01
uriParameters:
- name: subscriptionId
  in: path
  isRequired: true
  description: The unique identifier for a Microsoft Azure subscription.
  types:
  - uid: string
- name: resourceGroupName
  in: path
  isRequired: true
  description: The name of the resource group within the Azure subscription.
  types:
  - uid: string
- name: accountName
  in: path
  isRequired: true
  description: The Media Services account name.
  types:
  - uid: string
- name: transformName
  in: path
  isRequired: true
  description: The Transform name.
  types:
  - uid: string
- name: jobName
  in: path
  isRequired: true
  description: The Job name.
  types:
  - uid: string
- name: api-version
  in: query
  isRequired: true
  description: The version of the API to be used with the client request.
  types:
  - uid: string
responses:
- name: 200 OK
  description: OK
  types:
  - uid: Job
- name: Other Status Codes
  description: Detailed error information.
  types:
  - uid: ErrorResponse
requestHeader: []
definitions:
- name: Job
  description: A Job resource type. The progress and state can be obtained by polling a Job or subscribing to events using EventGrid.
  kind: object
  properties:
  - name: systemData
    isReadyOnly: true
    description: The system metadata relating to this resource.
    types:
    - uid: systemData
  - name: properties.created
    isReadyOnly: true
    description: The UTC date and time when the customer has created the Job, in 'YYYY-MM-DDThh:mm:ssZ' format.
    types:
    - uid: string
  - name: properties.state
    isReadyOnly: true
    description: The current state of the job.
    types:
    - uid: JobState
  - name: properties.description
    description: Optional customer supplied description of the Job.
    types:
    - uid: string
  - name: properties.input
    description: The inputs for the Job.
    types:
    - uid: JobInputClip
    - uid: JobInputs
    - uid: JobInputSequence
    - uid: JobInputAsset
    - uid: JobInputHttp
    typesTitle: JobInput
  - name: properties.lastModified
    isReadyOnly: true
    description: The UTC date and time when the customer has last updated the Job, in 'YYYY-MM-DDThh:mm:ssZ' format.
    types:
    - uid: string
  - name: properties.outputs
    description: The outputs for the Job.
    types:
    - uid: JobOutputAsset
      isArray: true
    typesTitle: JobOutput[]
  - name: properties.priority
    description: Priority with which the job should be processed. Higher priority jobs are processed before lower priority jobs. If not set, the default is normal.
    types:
    - uid: Priority
  - name: properties.correlationData
    description: Customer provided key, value pairs that will be returned in Job and JobOutput state events.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: properties.startTime
    isReadyOnly: true
    description: The UTC date and time at which this Job began processing.
    types:
    - uid: string
  - name: properties.endTime
    isReadyOnly: true
    description: The UTC date and time at which this Job finished processing.
    types:
    - uid: string
  - name: id
    isReadyOnly: true
    description: Fully qualified resource ID for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
    types:
    - uid: string
  - name: name
    isReadyOnly: true
    description: The name of the resource
    types:
    - uid: string
  - name: type
    isReadyOnly: true
    description: The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
    types:
    - uid: string
- name: ErrorResponse
  description: Error response
  kind: object
  properties:
  - name: error
    description: The error object.
    types:
    - uid: ErrorDetail
- name: systemData
  description: Metadata pertaining to creation and last modification of the resource.
  kind: object
  properties:
  - name: createdBy
    description: The identity that created the resource.
    types:
    - uid: string
  - name: createdByType
    description: The type of identity that created the resource.
    types:
    - uid: createdByType
  - name: createdAt
    description: The timestamp of resource creation (UTC).
    types:
    - uid: string
  - name: lastModifiedBy
    description: The identity that last modified the resource.
    types:
    - uid: string
  - name: lastModifiedByType
    description: The type of identity that last modified the resource.
    types:
    - uid: createdByType
  - name: lastModifiedAt
    description: The timestamp of resource last modification (UTC)
    types:
    - uid: string
- name: JobState
  description: Describes the state of the JobOutput.
  kind: enum
  properties:
  - name: Canceled
    description: The job was canceled. This is a final state for the job.
    types:
    - uid: string
  - name: Canceling
    description: The job is in the process of being canceled. This is a transient state for the job.
    types:
    - uid: string
  - name: Error
    description: The job has encountered an error. This is a final state for the job.
    types:
    - uid: string
  - name: Finished
    description: The job is finished. This is a final state for the job.
    types:
    - uid: string
  - name: Processing
    description: The job is processing. This is a transient state for the job.
    types:
    - uid: string
  - name: Queued
    description: The job is in a queued state, waiting for resources to become available. This is a transient state.
    types:
    - uid: string
  - name: Scheduled
    description: The job is being scheduled to run on an available resource. This is a transient state, between queued and processing states.
    types:
    - uid: string
- name: Priority
  description: Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing TransformOutputs. The default priority is Normal.
  kind: enum
  properties:
  - name: Low
    description: Used for TransformOutputs that can be generated after Normal and High priority TransformOutputs.
    types:
    - uid: string
  - name: Normal
    description: Used for TransformOutputs that can be generated at Normal priority.
    types:
    - uid: string
  - name: High
    description: Used for TransformOutputs that should take precedence over others.
    types:
    - uid: string
- name: ErrorDetail
  description: The error detail.
  kind: object
  properties:
  - name: code
    isReadyOnly: true
    description: The error code.
    types:
    - uid: string
  - name: message
    isReadyOnly: true
    description: The error message.
    types:
    - uid: string
  - name: target
    isReadyOnly: true
    description: The error target.
    types:
    - uid: string
  - name: details
    isReadyOnly: true
    description: The error details.
    types:
    - uid: ErrorDetail
      isArray: true
  - name: additionalInfo
    isReadyOnly: true
    description: The error additional info.
    types:
    - uid: ErrorAdditionalInfo
      isArray: true
- name: createdByType
  description: The type of identity that created the resource.
  kind: enum
  properties:
  - name: User
    types:
    - uid: string
  - name: Application
    types:
    - uid: string
  - name: ManagedIdentity
    types:
    - uid: string
  - name: Key
    types:
    - uid: string
- name: JobInputClip
  description: Represents input files for a Job.
  kind: object
  properties:
  - name: files
    description: List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure.
    types:
    - uid: string
      isArray: true
  - name: start
    description: Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: end
    description: Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: label
    description: A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
    types:
    - uid: string
  - name: inputDefinitions
    description: Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
    types:
    - uid: FromAllInputFile
      isArray: true
    - uid: FromEachInputFile
      isArray: true
    - uid: InputFile
      isArray: true
    typesTitle: InputDefinition[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobInputClip'
    typesTitle: string
- name: JobInputs
  description: Describes a list of inputs to a Job.
  kind: object
  properties:
  - name: inputs
    description: List of inputs to a Job.
    types:
    - uid: JobInputClip
      isArray: true
    - uid: JobInputs
      isArray: true
    - uid: JobInputSequence
      isArray: true
    - uid: JobInputAsset
      isArray: true
    - uid: JobInputHttp
      isArray: true
    typesTitle: JobInput[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobInputs'
    typesTitle: string
- name: JobInputSequence
  description: A Sequence contains an ordered list of Clips where each clip is a JobInput.  The Sequence will be treated as a single input.
  kind: object
  properties:
  - name: inputs
    description: JobInputs that make up the timeline.
    types:
    - uid: JobInputAsset
      isArray: true
    - uid: JobInputHttp
      isArray: true
    typesTitle: JobInputClip[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobInputSequence'
    typesTitle: string
- name: JobInputAsset
  description: Represents an Asset for input into a Job.
  kind: object
  properties:
  - name: assetName
    description: The name of the input Asset.
    types:
    - uid: string
  - name: files
    description: List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure.
    types:
    - uid: string
      isArray: true
  - name: start
    description: Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: end
    description: Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: label
    description: A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
    types:
    - uid: string
  - name: inputDefinitions
    description: Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
    types:
    - uid: FromAllInputFile
      isArray: true
    - uid: FromEachInputFile
      isArray: true
    - uid: InputFile
      isArray: true
    typesTitle: InputDefinition[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobInputAsset'
    typesTitle: string
- name: JobInputHttp
  description: Represents HTTPS job input.
  kind: object
  properties:
  - name: baseUri
    description: Base URI for HTTPS job input. It will be concatenated with provided file names. If no base uri is given, then the provided file list is assumed to be fully qualified uris. Maximum length of 4000 characters. The query strings will not be returned in service responses to prevent sensitive data exposure.
    types:
    - uid: string
  - name: files
    description: List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure.
    types:
    - uid: string
      isArray: true
  - name: start
    description: Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: end
    description: Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
    types:
    - uid: AbsoluteClipTime
    - uid: UtcClipTime
    typesTitle: ClipTime
  - name: label
    description: A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
    types:
    - uid: string
  - name: inputDefinitions
    description: Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
    types:
    - uid: FromAllInputFile
      isArray: true
    - uid: FromEachInputFile
      isArray: true
    - uid: InputFile
      isArray: true
    typesTitle: InputDefinition[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobInputHttp'
    typesTitle: string
- name: JobOutputAsset
  description: Represents an Asset used as a JobOutput.
  kind: object
  properties:
  - name: assetName
    description: The name of the output Asset.
    types:
    - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JobOutputAsset'
    typesTitle: string
  - name: error
    isReadyOnly: true
    description: If the JobOutput is in the Error state, it contains the details of the error.
    types:
    - uid: JobError
  - name: presetOverride
    description: A preset used to override the preset in the corresponding transform output.
    types:
    - uid: FaceDetectorPreset
    - uid: AudioAnalyzerPreset
    - uid: BuiltInStandardEncoderPreset
    - uid: StandardEncoderPreset
    - uid: VideoAnalyzerPreset
    typesTitle: Preset
  - name: state
    isReadyOnly: true
    description: Describes the state of the JobOutput.
    types:
    - uid: JobState
  - name: progress
    isReadyOnly: true
    description: If the JobOutput is in a Processing state, this contains the Job completion percentage. The value is an estimate and not intended to be used to predict Job completion times. To determine if the JobOutput is complete, use the State property.
    types:
    - uid: integer
  - name: label
    description: A label that is assigned to a JobOutput in order to help uniquely identify it. This is useful when your Transform has more than one TransformOutput, whereby your Job has more than one JobOutput. In such cases, when you submit the Job, you will add two or more JobOutputs, in the same order as TransformOutputs in the Transform. Subsequently, when you retrieve the Job, either through events or on a GET request, you can use the label to easily identify the JobOutput. If a label is not provided, a default value of '{presetName}_{outputIndex}' will be used, where the preset name is the name of the preset in the corresponding TransformOutput and the output index is the relative index of the this JobOutput within the Job. Note that this index is the same as the relative index of the corresponding TransformOutput within its Transform.
    types:
    - uid: string
  - name: startTime
    isReadyOnly: true
    description: The UTC date and time at which this Job Output began processing.
    types:
    - uid: string
  - name: endTime
    isReadyOnly: true
    description: The UTC date and time at which this Job Output finished processing.
    types:
    - uid: string
- name: ErrorAdditionalInfo
  description: The resource management error additional info.
  kind: object
  properties:
  - name: type
    isReadyOnly: true
    description: The additional info type.
    types:
    - uid: string
  - name: info
    isReadyOnly: true
    description: The additional info.
    types:
    - uid: object
- name: JobError
  description: Details of JobOutput errors.
  kind: object
  properties:
  - name: code
    isReadyOnly: true
    description: Error code describing the error.
    types:
    - uid: JobErrorCode
  - name: message
    isReadyOnly: true
    description: A human-readable language-dependent representation of the error.
    types:
    - uid: string
  - name: category
    isReadyOnly: true
    description: Helps with categorization of errors.
    types:
    - uid: JobErrorCategory
  - name: retry
    isReadyOnly: true
    description: Indicates that it may be possible to retry the Job. If retry is unsuccessful, please contact Azure support via Azure Portal.
    types:
    - uid: JobRetry
  - name: details
    isReadyOnly: true
    description: An array of details about specific errors that led to this reported error.
    types:
    - uid: JobErrorDetail
      isArray: true
- name: AbsoluteClipTime
  description: Specifies the clip time as an absolute time position in the media file.  The absolute time can point to a different position depending on whether the media file starts from a timestamp of zero or not.
  kind: object
  properties:
  - name: time
    description: The time position on the timeline of the input media. It is usually specified as an ISO8601 period. e.g PT30S for 30 seconds.
    types:
    - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.AbsoluteClipTime'
    typesTitle: string
- name: UtcClipTime
  description: Specifies the clip time as a Utc time position in the media file.  The Utc time can point to a different position depending on whether the media file starts from a timestamp of zero or not.
  kind: object
  properties:
  - name: time
    description: The time position on the timeline of the input media based on Utc time.
    types:
    - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.UtcClipTime'
    typesTitle: string
- name: FromAllInputFile
  description: An InputDefinition that looks across all of the files provided to select tracks specified by the IncludedTracks property. Generally used with the AudioTrackByAttribute and VideoTrackByAttribute to allow selection of a single track across a set of input files.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.FromAllInputFile'
    typesTitle: string
  - name: includedTracks
    description: The list of TrackDescriptors which define the metadata and selection of tracks in the input.
    types:
    - uid: AudioTrackDescriptor
      isArray: true
    - uid: VideoTrackDescriptor
      isArray: true
    - uid: SelectVideoTrackByAttribute
      isArray: true
    - uid: SelectVideoTrackById
      isArray: true
    - uid: SelectAudioTrackByAttribute
      isArray: true
    - uid: SelectAudioTrackById
      isArray: true
    typesTitle: TrackDescriptor[]
- name: FromEachInputFile
  description: An InputDefinition that looks at each input file provided to select tracks specified by the IncludedTracks property. Generally used with the AudioTrackByAttribute and VideoTrackByAttribute to select tracks from each file given.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.FromEachInputFile'
    typesTitle: string
  - name: includedTracks
    description: The list of TrackDescriptors which define the metadata and selection of tracks in the input.
    types:
    - uid: AudioTrackDescriptor
      isArray: true
    - uid: VideoTrackDescriptor
      isArray: true
    - uid: SelectVideoTrackByAttribute
      isArray: true
    - uid: SelectVideoTrackById
      isArray: true
    - uid: SelectAudioTrackByAttribute
      isArray: true
    - uid: SelectAudioTrackById
      isArray: true
    typesTitle: TrackDescriptor[]
- name: InputFile
  description: An InputDefinition for a single file.  TrackSelections are scoped to the file specified.
  kind: object
  properties:
  - name: filename
    description: Name of the file that this input definition applies to.
    types:
    - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.InputFile'
    typesTitle: string
  - name: includedTracks
    description: The list of TrackDescriptors which define the metadata and selection of tracks in the input.
    types:
    - uid: AudioTrackDescriptor
      isArray: true
    - uid: VideoTrackDescriptor
      isArray: true
    - uid: SelectVideoTrackByAttribute
      isArray: true
    - uid: SelectVideoTrackById
      isArray: true
    - uid: SelectAudioTrackByAttribute
      isArray: true
    - uid: SelectAudioTrackById
      isArray: true
    typesTitle: TrackDescriptor[]
- name: JobErrorCode
  description: Error code describing the error.
  kind: enum
  properties:
  - name: ServiceError
    description: Fatal service error, please contact support.
    types:
    - uid: string
  - name: ServiceTransientError
    description: Transient error, please retry, if retry is unsuccessful, please contact support.
    types:
    - uid: string
  - name: DownloadNotAccessible
    description: While trying to download the input files, the files were not accessible, please check the availability of the source.
    types:
    - uid: string
  - name: DownloadTransientError
    description: While trying to download the input files, there was an issue during transfer (storage service, network errors), see details and check your source.
    types:
    - uid: string
  - name: UploadNotAccessible
    description: While trying to upload the output files, the destination was not reachable, please check the availability of the destination.
    types:
    - uid: string
  - name: UploadTransientError
    description: While trying to upload the output files, there was an issue during transfer (storage service, network errors), see details and check your destination.
    types:
    - uid: string
  - name: ConfigurationUnsupported
    description: There was a problem with the combination of input files and the configuration settings applied, fix the configuration settings and retry with the same input, or change input to match the configuration.
    types:
    - uid: string
  - name: ContentMalformed
    description: 'There was a problem with the input content (for example: zero byte files, or corrupt/non-decodable files), check the input files.'
    types:
    - uid: string
  - name: ContentUnsupported
    description: There was a problem with the format of the input (not valid media file, or an unsupported file/codec), check the validity of the input files.
    types:
    - uid: string
- name: JobErrorCategory
  description: Helps with categorization of errors.
  kind: enum
  properties:
  - name: Service
    description: The error is service related.
    types:
    - uid: string
  - name: Download
    description: The error is download related.
    types:
    - uid: string
  - name: Upload
    description: The error is upload related.
    types:
    - uid: string
  - name: Configuration
    description: The error is configuration related.
    types:
    - uid: string
  - name: Content
    description: The error is related to data in the input files.
    types:
    - uid: string
- name: JobRetry
  description: Indicates that it may be possible to retry the Job. If retry is unsuccessful, please contact Azure support via Azure Portal.
  kind: enum
  properties:
  - name: DoNotRetry
    description: Issue needs to be investigated and then the job resubmitted with corrections or retried once the underlying issue has been corrected.
    types:
    - uid: string
  - name: MayRetry
    description: Issue may be resolved after waiting for a period of time and resubmitting the same Job.
    types:
    - uid: string
- name: JobErrorDetail
  description: Details of JobOutput errors.
  kind: object
  properties:
  - name: code
    isReadyOnly: true
    description: Code describing the error detail.
    types:
    - uid: string
  - name: message
    isReadyOnly: true
    description: A human-readable representation of the error.
    types:
    - uid: string
- name: FaceDetectorPreset
  description: Describes all the settings to be used when analyzing a video in order to detect (and optionally redact) all the faces present.
  kind: object
  properties:
  - name: resolution
    description: Specifies the maximum resolution at which your video is analyzed. The default behavior is "SourceResolution," which will keep the input video at its original resolution when analyzed. Using "StandardDefinition" will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to "StandardDefinition" will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end up being too small in the resized video may not be detected.
    types:
    - uid: AnalysisResolution
  - name: mode
    description: 'This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs) detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction.'
    types:
    - uid: FaceRedactorMode
  - name: blurType
    description: Blur type
    types:
    - uid: BlurType
  - name: experimentalOptions
    description: Dictionary containing key value pairs for parameters not exposed in the preset itself
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.FaceDetectorPreset'
    typesTitle: string
- name: AudioAnalyzerPreset
  description: The Audio Analyzer preset applies a pre-defined set of AI-based analysis operations, including speech transcription. Currently, the preset supports processing of content with a single audio track.
  kind: object
  properties:
  - name: audioLanguage
    description: "The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US').  If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode::Basic, since automatic language detection is not included in basic mode. If the language isn't specified or set to null, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'.\" The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463"
    types:
    - uid: string
  - name: mode
    description: Determines the set of audio analysis operations to be performed. If unspecified, the Standard AudioAnalysisMode would be chosen.
    types:
    - uid: AudioAnalysisMode
  - name: experimentalOptions
    description: Dictionary containing key value pairs for parameters not exposed in the preset itself
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.AudioAnalyzerPreset'
    typesTitle: string
- name: BuiltInStandardEncoderPreset
  description: Describes a built-in preset for encoding the input video with the Standard Encoder.
  kind: object
  properties:
  - name: configurations
    description: Optional configuration settings for encoder. Configurations is only supported for ContentAwareEncoding and H265ContentAwareEncoding BuiltInStandardEncoderPreset.
    types:
    - uid: PresetConfigurations
  - name: presetName
    description: The built-in preset to be used for encoding videos.
    types:
    - uid: EncoderNamedPreset
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.BuiltInStandardEncoderPreset'
    typesTitle: string
- name: StandardEncoderPreset
  description: Describes all the settings to be used when encoding the input video with the Standard Encoder.
  kind: object
  properties:
  - name: filters
    description: One or more filtering operations that are applied to the input media before encoding.
    types:
    - uid: Filters
  - name: codecs
    description: The list of codecs to be used when encoding the input video.
    types:
    - uid: Audio
      isArray: true
    - uid: Video
      isArray: true
    - uid: CopyVideo
      isArray: true
    - uid: CopyAudio
      isArray: true
    - uid: H265Video
      isArray: true
    - uid: Image
      isArray: true
    - uid: H264Video
      isArray: true
    - uid: JpgImage
      isArray: true
    - uid: PngImage
      isArray: true
    - uid: AacAudio
      isArray: true
    typesTitle: Codec[]
  - name: formats
    description: The list of outputs to be produced by the encoder.
    types:
    - uid: ImageFormat
      isArray: true
    - uid: MultiBitrateFormat
      isArray: true
    - uid: Mp4Format
      isArray: true
    - uid: TransportStreamFormat
      isArray: true
    - uid: JpgFormat
      isArray: true
    - uid: PngFormat
      isArray: true
    typesTitle: Format[]
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.StandardEncoderPreset'
    typesTitle: string
- name: VideoAnalyzerPreset
  description: A video analyzer preset that extracts insights (rich metadata) from both audio and video, and outputs a JSON format file.
  kind: object
  properties:
  - name: insightsToExtract
    description: Defines the type of insights that you want the service to generate. The allowed values are 'AudioInsightsOnly', 'VideoInsightsOnly', and 'AllInsights'. The default is AllInsights. If you set this to AllInsights and the input is audio only, then only audio insights are generated. Similarly if the input is video only, then only video insights are generated. It is recommended that you not use AudioInsightsOnly if you expect some of your inputs to be video only; or use VideoInsightsOnly if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out.
    types:
    - uid: InsightsType
  - name: audioLanguage
    description: "The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US').  If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode::Basic, since automatic language detection is not included in basic mode. If the language isn't specified or set to null, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to 'en-US'.\" The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463"
    types:
    - uid: string
  - name: mode
    description: Determines the set of audio analysis operations to be performed. If unspecified, the Standard AudioAnalysisMode would be chosen.
    types:
    - uid: AudioAnalysisMode
  - name: experimentalOptions
    description: Dictionary containing key value pairs for parameters not exposed in the preset itself
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.VideoAnalyzerPreset'
    typesTitle: string
- name: AnalysisResolution
  description: Specifies the maximum resolution at which your video is analyzed. The default behavior is "SourceResolution," which will keep the input video at its original resolution when analyzed. Using "StandardDefinition" will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to "StandardDefinition" will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics for details). However, faces that end up being too small in the resized video may not be detected.
  kind: enum
  properties:
  - name: SourceResolution
    types:
    - uid: string
  - name: StandardDefinition
    types:
    - uid: string
- name: FaceRedactorMode
  description: 'This mode provides the ability to choose between the following settings: 1) Analyze - For detection only.This mode generates a metadata JSON file marking appearances of faces throughout the video.Where possible, appearances of the same person are assigned the same ID. 2) Combined - Additionally redacts(blurs) detected faces. 3) Redact - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces.It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction.'
  kind: enum
  properties:
  - name: Analyze
    description: Analyze mode detects faces and outputs a metadata file with the results. Allows editing of the metadata file before faces are blurred with Redact mode.
    types:
    - uid: string
  - name: Redact
    description: Redact mode consumes the metadata file from Analyze mode and redacts the faces found.
    types:
    - uid: string
  - name: Combined
    description: Combined mode does the Analyze and Redact steps in one pass when editing the analyzed faces is not desired.
    types:
    - uid: string
- name: BlurType
  description: Blur type
  kind: enum
  properties:
  - name: Box
    description: 'Box: debug filter, bounding box only'
    types:
    - uid: string
  - name: Low
    description: 'Low: box-car blur filter'
    types:
    - uid: string
  - name: Med
    description: 'Med: Gaussian blur filter'
    types:
    - uid: string
  - name: High
    description: 'High: Confuse blur filter'
    types:
    - uid: string
  - name: Black
    description: 'Black: Black out filter'
    types:
    - uid: string
- name: AudioAnalysisMode
  description: Determines the set of audio analysis operations to be performed. If unspecified, the Standard AudioAnalysisMode would be chosen.
  kind: enum
  properties:
  - name: Standard
    description: Performs all operations included in the Basic mode, additionally performing language detection and speaker diarization.
    types:
    - uid: string
  - name: Basic
    description: This mode performs speech-to-text transcription and generation of a VTT subtitle/caption file. The output of this mode includes an Insights JSON file including only the keywords, transcription,and timing information. Automatic language detection and speaker diarization are not included in this mode.
    types:
    - uid: string
- name: PresetConfigurations
  description: An object of optional configuration settings for encoder.
  kind: object
  properties:
  - name: complexity
    description: 'Allows you to configure the encoder settings to control the balance between speed and quality. Example: set Complexity as Speed for faster encoding but less compression efficiency.'
    types:
    - uid: Complexity
  - name: interleaveOutput
    description: 'Sets the interleave mode of the output to control how audio and video are stored in the container format. Example: set InterleavedOutput as NonInterleavedOutput to produce audio-only and video-only outputs in separate MP4 files.'
    types:
    - uid: InterleaveOutput
  - name: keyFrameIntervalInSeconds
    description: 'The key frame interval in seconds. Example: set KeyFrameIntervalInSeconds as 2 to reduce the playback buffering for some players.'
    types:
    - uid: number
  - name: maxBitrateBps
    description: 'The maximum bitrate in bits per second (threshold for the top video layer). Example: set MaxBitrateBps as 6000000 to avoid producing very high bitrate outputs for contents with high complexity.'
    types:
    - uid: integer
  - name: maxHeight
    description: 'The maximum height of output video layers. Example: set MaxHeight as 720 to produce output layers up to 720P even if the input is 4K.'
    types:
    - uid: integer
  - name: maxLayers
    description: 'The maximum number of output video layers. Example: set MaxLayers as 4 to make sure at most 4 output layers are produced to control the overall cost of the encoding job.'
    types:
    - uid: integer
  - name: minBitrateBps
    description: 'The minimum bitrate in bits per second (threshold for the bottom video layer). Example: set MinBitrateBps as 200000 to have a bottom layer that covers users with low network bandwidth.'
    types:
    - uid: integer
  - name: minHeight
    description: 'The minimum height of output video layers. Example: set MinHeight as 360 to avoid output layers of smaller resolutions like 180P.'
    types:
    - uid: integer
- name: EncoderNamedPreset
  description: The built-in preset to be used for encoding videos.
  kind: enum
  properties:
  - name: H264SingleBitrateSD
    description: Produces an MP4 file where the video is encoded with H.264 codec at 2200 kbps and a picture height of 480 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
  - name: H264SingleBitrate720p
    description: Produces an MP4 file where the video is encoded with H.264 codec at 4500 kbps and a picture height of 720 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
  - name: H264SingleBitrate1080p
    description: Produces an MP4 file where the video is encoded with H.264 codec at 6750 kbps and a picture height of 1080 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
  - name: AdaptiveStreaming
    description: Produces a set of GOP aligned MP4 files with H.264 video and stereo AAC audio. Auto-generates a bitrate ladder based on the input resolution, bitrate and frame rate. The auto-generated preset will never exceed the input resolution. For example, if the input is 720p, output will remain 720p at best.
    types:
    - uid: string
  - name: AACGoodQualityAudio
    description: Produces a single MP4 file containing only stereo audio encoded at 192 kbps.
    types:
    - uid: string
  - name: ContentAwareEncodingExperimental
    description: Exposes an experimental preset for content-aware encoding. Given any input content, the service attempts to automatically determine the optimal number of layers, appropriate bitrate and resolution settings for delivery by adaptive streaming. The underlying algorithms will continue to evolve over time. The output will contain MP4 files with video and audio interleaved.
    types:
    - uid: string
  - name: ContentAwareEncoding
    description: Produces a set of GOP-aligned MP4s by using content-aware encoding. Given any input content, the service performs an initial lightweight analysis of the input content, and uses the results to determine the optimal number of layers, appropriate bitrate and resolution settings for delivery by adaptive streaming. This preset is particularly effective for low and medium complexity videos, where the output files will be at lower bitrates but at a quality that still delivers a good experience to viewers. The output will contain MP4 files with video and audio interleaved.
    types:
    - uid: string
  - name: CopyAllBitrateNonInterleaved
    description: Copy all video and audio streams from the input asset as non-interleaved video and audio output files. This preset can be used to clip an existing asset or convert a group of key frame (GOP) aligned MP4 files as an asset that can be streamed.
    types:
    - uid: string
  - name: H264MultipleBitrate1080p
    description: Produces a set of 8 GOP-aligned MP4 files, ranging from 6000 kbps to 400 kbps, and stereo AAC audio. Resolution starts at 1080p and goes down to 180p.
    types:
    - uid: string
  - name: H264MultipleBitrate720p
    description: Produces a set of 6 GOP-aligned MP4 files, ranging from 3400 kbps to 400 kbps, and stereo AAC audio. Resolution starts at 720p and goes down to 180p.
    types:
    - uid: string
  - name: H264MultipleBitrateSD
    description: Produces a set of 5 GOP-aligned MP4 files, ranging from 1900kbps to 400 kbps, and stereo AAC audio. Resolution starts at 480p and goes down to 240p.
    types:
    - uid: string
  - name: H265ContentAwareEncoding
    description: Produces a set of GOP-aligned MP4s by using content-aware encoding. Given any input content, the service performs an initial lightweight analysis of the input content, and uses the results to determine the optimal number of layers, appropriate bitrate and resolution settings for delivery by adaptive streaming. This preset is particularly effective for low and medium complexity videos, where the output files will be at lower bitrates but at a quality that still delivers a good experience to viewers. The output will contain MP4 files with video and audio interleaved.
    types:
    - uid: string
  - name: H265AdaptiveStreaming
    description: Produces a set of GOP aligned MP4 files with H.265 video and stereo AAC audio. Auto-generates a bitrate ladder based on the input resolution, bitrate and frame rate. The auto-generated preset will never exceed the input resolution. For example, if the input is 720p, output will remain 720p at best.
    types:
    - uid: string
  - name: H265SingleBitrate720p
    description: Produces an MP4 file where the video is encoded with H.265 codec at 1800 kbps and a picture height of 720 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
  - name: H265SingleBitrate1080p
    description: Produces an MP4 file where the video is encoded with H.265 codec at 3500 kbps and a picture height of 1080 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
  - name: H265SingleBitrate4K
    description: Produces an MP4 file where the video is encoded with H.265 codec at 9500 kbps and a picture height of 2160 pixels, and the stereo audio is encoded with AAC-LC codec at 128 kbps.
    types:
    - uid: string
- name: Filters
  description: Describes all the filtering operations, such as de-interlacing, rotation etc. that are to be applied to the input media before encoding.
  kind: object
  properties:
  - name: deinterlace
    description: The de-interlacing settings.
    types:
    - uid: Deinterlace
  - name: rotation
    description: The rotation, if any, to be applied to the input video, before it is encoded. Default is Auto
    types:
    - uid: Rotation
  - name: crop
    description: The parameters for the rectangular window with which to crop the input video.
    types:
    - uid: Rectangle
  - name: overlays
    description: The properties of overlays to be applied to the input video. These could be audio, image or video overlays.
    types:
    - uid: AudioOverlay
      isArray: true
    - uid: VideoOverlay
      isArray: true
    typesTitle: Overlay[]
- name: InsightsType
  description: Defines the type of insights that you want the service to generate. The allowed values are 'AudioInsightsOnly', 'VideoInsightsOnly', and 'AllInsights'. The default is AllInsights. If you set this to AllInsights and the input is audio only, then only audio insights are generated. Similarly if the input is video only, then only video insights are generated. It is recommended that you not use AudioInsightsOnly if you expect some of your inputs to be video only; or use VideoInsightsOnly if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out.
  kind: enum
  properties:
  - name: AudioInsightsOnly
    description: Generate audio only insights. Ignore video even if present. Fails if no audio is present.
    types:
    - uid: string
  - name: VideoInsightsOnly
    description: Generate video only insights. Ignore audio if present. Fails if no video is present.
    types:
    - uid: string
  - name: AllInsights
    description: Generate both audio and video insights. Fails if either audio or video Insights fail.
    types:
    - uid: string
- name: AudioTrackDescriptor
  description: A TrackSelection to select audio tracks.
  kind: object
  properties:
  - name: channelMapping
    description: Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks.
    types:
    - uid: ChannelMapping
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.AudioTrackDescriptor'
    typesTitle: string
- name: VideoTrackDescriptor
  description: A TrackSelection to select video tracks.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.VideoTrackDescriptor'
    typesTitle: string
- name: SelectVideoTrackByAttribute
  description: Select video tracks from the input by specifying an attribute and an attribute filter.
  kind: object
  properties:
  - name: attribute
    description: The TrackAttribute to filter the tracks by.
    types:
    - uid: TrackAttribute
  - name: filter
    description: The type of AttributeFilter to apply to the TrackAttribute in order to select the tracks.
    types:
    - uid: AttributeFilter
  - name: filterValue
    description: "The value to filter the tracks by.  Only used when AttributeFilter.ValueEquals is specified for the Filter property. For TrackAttribute.Bitrate, this should be an integer value in bits per second (e.g: '1500000').  The TrackAttribute.Language is not supported for video tracks."
    types:
    - uid: string
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.SelectVideoTrackByAttribute'
    typesTitle: string
- name: SelectVideoTrackById
  description: Select video tracks from the input by specifying a track identifier.
  kind: object
  properties:
  - name: trackId
    description: Track identifier to select
    types:
    - uid: integer
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.SelectVideoTrackById'
    typesTitle: string
- name: SelectAudioTrackByAttribute
  description: Select audio tracks from the input by specifying an attribute and an attribute filter.
  kind: object
  properties:
  - name: attribute
    description: The TrackAttribute to filter the tracks by.
    types:
    - uid: TrackAttribute
  - name: filter
    description: The type of AttributeFilter to apply to the TrackAttribute in order to select the tracks.
    types:
    - uid: AttributeFilter
  - name: filterValue
    description: The value to filter the tracks by.  Only used when AttributeFilter.ValueEquals is specified for the Filter property.
    types:
    - uid: string
  - name: channelMapping
    description: Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks.
    types:
    - uid: ChannelMapping
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.SelectAudioTrackByAttribute'
    typesTitle: string
- name: SelectAudioTrackById
  description: Select audio tracks from the input by specifying a track identifier.
  kind: object
  properties:
  - name: trackId
    description: Track identifier to select
    types:
    - uid: integer
  - name: channelMapping
    description: Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks.
    types:
    - uid: ChannelMapping
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.SelectAudioTrackById'
    typesTitle: string
- name: Complexity
  description: 'Allows you to configure the encoder settings to control the balance between speed and quality. Example: set Complexity as Speed for faster encoding but less compression efficiency.'
  kind: enum
  properties:
  - name: Speed
    description: Configures the encoder to use settings optimized for faster encoding. Quality is sacrificed to decrease encoding time.
    types:
    - uid: string
  - name: Balanced
    description: Configures the encoder to use settings that achieve a balance between speed and quality.
    types:
    - uid: string
  - name: Quality
    description: Configures the encoder to use settings optimized to produce higher quality output at the expense of slower overall encode time.
    types:
    - uid: string
- name: InterleaveOutput
  description: 'Sets the interleave mode of the output to control how audio and video are stored in the container format. Example: set InterleavedOutput as NonInterleavedOutput to produce audio-only and video-only outputs in separate MP4 files.'
  kind: enum
  properties:
  - name: NonInterleavedOutput
    description: The output is video-only or audio-only.
    types:
    - uid: string
  - name: InterleavedOutput
    description: The output includes both audio and video.
    types:
    - uid: string
- name: Deinterlace
  description: Describes the de-interlacing settings.
  kind: object
  properties:
  - name: parity
    description: The field parity for de-interlacing, defaults to Auto.
    types:
    - uid: DeinterlaceParity
  - name: mode
    description: The deinterlacing mode. Defaults to AutoPixelAdaptive.
    types:
    - uid: DeinterlaceMode
- name: Rotation
  description: The rotation, if any, to be applied to the input video, before it is encoded. Default is Auto
  kind: enum
  properties:
  - name: Auto
    description: Automatically detect and rotate as needed.
    types:
    - uid: string
  - name: None
    description: Do not rotate the video.  If the output format supports it, any metadata about rotation is kept intact.
    types:
    - uid: string
  - name: Rotate0
    description: Do not rotate the video but remove any metadata about the rotation.
    types:
    - uid: string
  - name: Rotate90
    description: Rotate 90 degrees clockwise.
    types:
    - uid: string
  - name: Rotate180
    description: Rotate 180 degrees clockwise.
    types:
    - uid: string
  - name: Rotate270
    description: Rotate 270 degrees clockwise.
    types:
    - uid: string
- name: Rectangle
  description: Describes the properties of a rectangular window applied to the input media before processing it.
  kind: object
  properties:
  - name: left
    description: The number of pixels from the left-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
    types:
    - uid: string
  - name: top
    description: The number of pixels from the top-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
    types:
    - uid: string
  - name: width
    description: The width of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
    types:
    - uid: string
  - name: height
    description: The height of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
    types:
    - uid: string
- name: Audio
  description: Defines the common properties for all audio codecs.
  kind: object
  properties:
  - name: channels
    description: The number of channels in the audio.
    types:
    - uid: integer
  - name: samplingRate
    description: The sampling rate to use for encoding in hertz.
    types:
    - uid: integer
  - name: bitrate
    description: The bitrate, in bits per second, of the output encoded audio.
    types:
    - uid: integer
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.Audio'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: Video
  description: Describes the basic properties for encoding the input video.
  kind: object
  properties:
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.Video'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: CopyVideo
  description: A codec flag, which tells the encoder to copy the input video bitstream without re-encoding.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.CopyVideo'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: CopyAudio
  description: A codec flag, which tells the encoder to copy the input audio bitstream.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.CopyAudio'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: H265Video
  description: Describes all the properties for encoding a video with the H.265 codec.
  kind: object
  properties:
  - name: sceneChangeDetection
    description: Specifies whether or not the encoder should insert key frames at scene changes. If not specified, the default is false. This flag should be set to true only when the encoder is being configured to produce a single output video.
    types:
    - uid: boolean
  - name: complexity
    description: Tells the encoder how to choose its encoding settings.  Quality will provide for a higher compression ratio but at a higher cost and longer compute time.  Speed will produce a relatively larger file but is faster and more economical. The default value is Balanced.
    types:
    - uid: H265Complexity
  - name: layers
    description: The collection of output H.265 layers to be produced by the encoder.
    types:
    - uid: H265Layer
      isArray: true
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.H265Video'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: Image
  description: Describes the basic properties for generating thumbnails from the input video
  kind: object
  properties:
  - name: start
    description: The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}.
    types:
    - uid: string
  - name: step
    description: 'The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time.'
    types:
    - uid: string
  - name: range
    description: The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream.
    types:
    - uid: string
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.Image'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: H264Video
  description: Describes all the properties for encoding a video with the H.264 codec.
  kind: object
  properties:
  - name: complexity
    description: Tells the encoder how to choose its encoding settings. The default value is Balanced.
    types:
    - uid: H264Complexity
  - name: layers
    description: The collection of output H.264 layers to be produced by the encoder.
    types:
    - uid: H264Layer
      isArray: true
  - name: rateControlMode
    description: The video rate control mode
    types:
    - uid: H264RateControlMode
  - name: sceneChangeDetection
    description: Whether or not the encoder should insert key frames at scene changes. If not specified, the default is false. This flag should be set to true only when the encoder is being configured to produce a single output video.
    types:
    - uid: boolean
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.H264Video'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: JpgImage
  description: Describes the properties for producing a series of JPEG images from the input video.
  kind: object
  properties:
  - name: layers
    description: A collection of output JPEG image layers to be produced by the encoder.
    types:
    - uid: JpgLayer
      isArray: true
  - name: spriteColumn
    description: 'Sets the number of columns used in thumbnail sprite image.  The number of rows are automatically calculated and a VTT file is generated with the coordinate mappings for each thumbnail in the sprite. Note: this value should be a positive integer and a proper value is recommended so that the output image resolution will not go beyond JPEG maximum pixel resolution limit 65535x65535.'
    types:
    - uid: integer
  - name: start
    description: The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}.
    types:
    - uid: string
  - name: step
    description: 'The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time.'
    types:
    - uid: string
  - name: range
    description: The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream.
    types:
    - uid: string
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JpgImage'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: PngImage
  description: Describes the properties for producing a series of PNG images from the input video.
  kind: object
  properties:
  - name: layers
    description: A collection of output PNG image layers to be produced by the encoder.
    types:
    - uid: PngLayer
      isArray: true
  - name: start
    description: The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}.
    types:
    - uid: string
  - name: step
    description: 'The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time.'
    types:
    - uid: string
  - name: range
    description: The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream.
    types:
    - uid: string
  - name: keyFrameInterval
    description: The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting.
    types:
    - uid: string
  - name: stretchMode
    description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
    types:
    - uid: StretchMode
  - name: syncMode
    description: The Video Sync Mode
    types:
    - uid: VideoSyncMode
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.PngImage'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: AacAudio
  description: Describes Advanced Audio Codec (AAC) audio encoding settings.
  kind: object
  properties:
  - name: profile
    description: The encoding profile to be used when encoding audio with AAC.
    types:
    - uid: AacAudioProfile
  - name: channels
    description: The number of channels in the audio.
    types:
    - uid: integer
  - name: samplingRate
    description: The sampling rate to use for encoding in hertz.
    types:
    - uid: integer
  - name: bitrate
    description: The bitrate, in bits per second, of the output encoded audio.
    types:
    - uid: integer
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.AacAudio'
    typesTitle: string
  - name: label
    description: An optional label for the codec. The label can be used to control muxing behavior.
    types:
    - uid: string
- name: ImageFormat
  description: Describes the properties for an output image file.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.ImageFormat'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: MultiBitrateFormat
  description: Describes the properties for producing a collection of GOP aligned multi-bitrate files. The default behavior is to produce one output file for each video layer which is muxed together with all the audios. The exact output files produced can be controlled by specifying the outputFiles collection.
  kind: object
  properties:
  - name: outputFiles
    description: The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
    types:
    - uid: OutputFile
      isArray: true
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.MultiBitrateFormat'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: Mp4Format
  description: Describes the properties for an output ISO MP4 file.
  kind: object
  properties:
  - name: outputFiles
    description: The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
    types:
    - uid: OutputFile
      isArray: true
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.Mp4Format'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: TransportStreamFormat
  description: Describes the properties for generating an MPEG-2 Transport Stream (ISO/IEC 13818-1) output video file(s).
  kind: object
  properties:
  - name: outputFiles
    description: The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
    types:
    - uid: OutputFile
      isArray: true
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.TransportStreamFormat'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: JpgFormat
  description: Describes the settings for producing JPEG thumbnails.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.JpgFormat'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: PngFormat
  description: Describes the settings for producing PNG thumbnails.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.PngFormat'
    typesTitle: string
  - name: filenamePattern
    description: 'The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.'
    types:
    - uid: string
- name: ChannelMapping
  description: Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks.
  kind: enum
  properties:
  - name: FrontLeft
    description: The Front Left Channel.
    types:
    - uid: string
  - name: FrontRight
    description: The Front Right Channel.
    types:
    - uid: string
  - name: Center
    description: The Center Channel.
    types:
    - uid: string
  - name: LowFrequencyEffects
    description: Low Frequency Effects Channel.  Sometimes referred to as the Subwoofer.
    types:
    - uid: string
  - name: BackLeft
    description: The Back Left Channel.  Sometimes referred to as the Left Surround Channel.
    types:
    - uid: string
  - name: BackRight
    description: The Back Right Channel.  Sometimes referred to as the Right Surround Channel.
    types:
    - uid: string
  - name: StereoLeft
    description: The Left Stereo channel.  Sometimes referred to as Down Mix Left.
    types:
    - uid: string
  - name: StereoRight
    description: The Right Stereo channel.  Sometimes referred to as Down Mix Right.
    types:
    - uid: string
- name: TrackAttribute
  description: The TrackAttribute to filter the tracks by.
  kind: enum
  properties:
  - name: Bitrate
    description: The bitrate of the track.
    types:
    - uid: string
  - name: Language
    description: The language of the track.
    types:
    - uid: string
- name: AttributeFilter
  description: The type of AttributeFilter to apply to the TrackAttribute in order to select the tracks.
  kind: enum
  properties:
  - name: All
    description: All tracks will be included.
    types:
    - uid: string
  - name: Top
    description: The first track will be included when the attribute is sorted in descending order.  Generally used to select the largest bitrate.
    types:
    - uid: string
  - name: Bottom
    description: The first track will be included when the attribute is sorted in ascending order.  Generally used to select the smallest bitrate.
    types:
    - uid: string
  - name: ValueEquals
    description: Any tracks that have an attribute equal to the value given will be included.
    types:
    - uid: string
- name: DeinterlaceParity
  description: The field parity for de-interlacing, defaults to Auto.
  kind: enum
  properties:
  - name: Auto
    description: Automatically detect the order of fields
    types:
    - uid: string
  - name: TopFieldFirst
    description: Apply top field first processing of input video.
    types:
    - uid: string
  - name: BottomFieldFirst
    description: Apply bottom field first processing of input video.
    types:
    - uid: string
- name: DeinterlaceMode
  description: The deinterlacing mode. Defaults to AutoPixelAdaptive.
  kind: enum
  properties:
  - name: Off
    description: Disables de-interlacing of the source video.
    types:
    - uid: string
  - name: AutoPixelAdaptive
    description: Apply automatic pixel adaptive de-interlacing on each frame in the input video.
    types:
    - uid: string
- name: AudioOverlay
  description: Describes the properties of an audio overlay.
  kind: object
  properties:
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.AudioOverlay'
    typesTitle: string
  - name: inputLabel
    description: The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats.
    types:
    - uid: string
  - name: start
    description: The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video.
    types:
    - uid: string
  - name: end
    description: The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, PT30S to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration.
    types:
    - uid: string
  - name: fadeInDuration
    description: The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S).
    types:
    - uid: string
  - name: fadeOutDuration
    description: The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S).
    types:
    - uid: string
  - name: audioGainLevel
    description: The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0.
    types:
    - uid: number
- name: VideoOverlay
  description: Describes the properties of a video overlay.
  kind: object
  properties:
  - name: position
    description: The location in the input video where the overlay is applied.
    types:
    - uid: Rectangle
  - name: opacity
    description: The opacity of the overlay. This is a value in the range [0 - 1.0]. Default is 1.0 which mean the overlay is opaque.
    types:
    - uid: number
  - name: cropRectangle
    description: An optional rectangular window used to crop the overlay image or video.
    types:
    - uid: Rectangle
  - name: '@odata.type'
    description: The discriminator for derived types.
    types:
    - uid: '#Microsoft.Media.VideoOverlay'
    typesTitle: string
  - name: inputLabel
    description: The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats.
    types:
    - uid: string
  - name: start
    description: The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video.
    types:
    - uid: string
  - name: end
    description: The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, PT30S to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration.
    types:
    - uid: string
  - name: fadeInDuration
    description: The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S).
    types:
    - uid: string
  - name: fadeOutDuration
    description: The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S).
    types:
    - uid: string
  - name: audioGainLevel
    description: The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0.
    types:
    - uid: number
- name: StretchMode
  description: The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
  kind: enum
  properties:
  - name: None
    description: Strictly respect the output resolution without considering the pixel aspect ratio or display aspect ratio of the input video.
    types:
    - uid: string
  - name: AutoSize
    description: Override the output resolution, and change it to match the display aspect ratio of the input, without padding. For example, if the input is 1920x1080 and the encoding preset asks for 1280x1280, then the value in the preset is overridden, and the output will be at 1280x720, which maintains the input aspect ratio of 16:9.
    types:
    - uid: string
  - name: AutoFit
    description: Pad the output (with either letterbox or pillar box) to honor the output resolution, while ensuring that the active video region in the output has the same aspect ratio as the input. For example, if the input is 1920x1080 and the encoding preset asks for 1280x1280, then the output will be at 1280x1280, which contains an inner rectangle of 1280x720 at aspect ratio of 16:9, and pillar box regions 280 pixels wide at the left and right.
    types:
    - uid: string
- name: VideoSyncMode
  description: The Video Sync Mode
  kind: enum
  properties:
  - name: Auto
    description: This is the default method. Chooses between Cfr and Vfr depending on muxer capabilities. For output format MP4, the default mode is Cfr.
    types:
    - uid: string
  - name: Passthrough
    description: 'The presentation timestamps on frames are passed through from the input file to the output file writer. Recommended when the input source has variable frame rate, and are attempting to produce multiple layers for adaptive streaming in the output which have aligned GOP boundaries. Note: if two or more frames in the input have duplicate timestamps, then the output will also have the same behavior'
    types:
    - uid: string
  - name: Cfr
    description: Input frames will be repeated and/or dropped as needed to achieve exactly the requested constant frame rate. Recommended when the output frame rate is explicitly set at a specified value
    types:
    - uid: string
  - name: Vfr
    description: Similar to the Passthrough mode, but if the input has frames that have duplicate timestamps, then only one frame is passed through to the output, and others are dropped. Recommended when the number of output frames is expected to be equal to the number of input frames. For example, the output is used to calculate a quality metric like PSNR against the input
    types:
    - uid: string
- name: H265Complexity
  description: Tells the encoder how to choose its encoding settings.  Quality will provide for a higher compression ratio but at a higher cost and longer compute time.  Speed will produce a relatively larger file but is faster and more economical. The default value is Balanced.
  kind: enum
  properties:
  - name: Speed
    description: Tells the encoder to use settings that are optimized for faster encoding. Quality is sacrificed to decrease encoding time.
    types:
    - uid: string
  - name: Balanced
    description: Tells the encoder to use settings that achieve a balance between speed and quality.
    types:
    - uid: string
  - name: Quality
    description: Tells the encoder to use settings that are optimized to produce higher quality output at the expense of slower overall encode time.
    types:
    - uid: string
- name: H265Layer
  description: Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.265 video codec.
  kind: object
  properties:
  - name: profile
    description: We currently support Main. Default is Auto.
    types:
    - uid: H265VideoProfile
  - name: level
    description: We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.265 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
    types:
    - uid: string
  - name: bufferWindow
    description: The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S).
    types:
    - uid: string
  - name: crf
    description: The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default value is 28.
    types:
    - uid: number
  - name: referenceFrames
    description: The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.
    types:
    - uid: integer
  - name: bitrate
    description: 'The average bitrate in bits per second at which to encode the input video when generating this layer. For example: a target bitrate of 3000Kbps or 3Mbps means this value should be 3000000 This is a required field.'
    types:
    - uid: integer
  - name: maxBitrate
    description: The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate.
    types:
    - uid: integer
  - name: bFrames
    description: The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level.
    types:
    - uid: integer
  - name: frameRate
    description: The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video.
    types:
    - uid: string
  - name: slices
    description: The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame.
    types:
    - uid: integer
  - name: adaptiveBFrame
    description: Specifies whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use.
    types:
    - uid: boolean
  - name: width
    description: The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
    types:
    - uid: string
  - name: height
    description: The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
    types:
    - uid: string
  - name: label
    description: The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
    types:
    - uid: string
- name: H264Complexity
  description: Tells the encoder how to choose its encoding settings. The default value is Balanced.
  kind: enum
  properties:
  - name: Speed
    description: Tells the encoder to use settings that are optimized for faster encoding. Quality is sacrificed to decrease encoding time.
    types:
    - uid: string
  - name: Balanced
    description: Tells the encoder to use settings that achieve a balance between speed and quality.
    types:
    - uid: string
  - name: Quality
    description: Tells the encoder to use settings that are optimized to produce higher quality output at the expense of slower overall encode time.
    types:
    - uid: string
- name: H264Layer
  description: Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.264 video codec.
  kind: object
  properties:
  - name: profile
    description: We currently support Baseline, Main, High, High422, High444. Default is Auto.
    types:
    - uid: H264VideoProfile
  - name: level
    description: We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
    types:
    - uid: string
  - name: bufferWindow
    description: The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S).
    types:
    - uid: string
  - name: crf
    description: The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default value is 23.
    types:
    - uid: number
  - name: referenceFrames
    description: The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.
    types:
    - uid: integer
  - name: entropyMode
    description: The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the profile and level.
    types:
    - uid: EntropyMode
  - name: bitrate
    description: The average bitrate in bits per second at which to encode the input video when generating this layer. This is a required field.
    types:
    - uid: integer
  - name: maxBitrate
    description: The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate.
    types:
    - uid: integer
  - name: bFrames
    description: The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level.
    types:
    - uid: integer
  - name: frameRate
    description: The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video.
    types:
    - uid: string
  - name: slices
    description: The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame.
    types:
    - uid: integer
  - name: adaptiveBFrame
    description: Whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use.
    types:
    - uid: boolean
  - name: width
    description: The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
    types:
    - uid: string
  - name: height
    description: The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
    types:
    - uid: string
  - name: label
    description: The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
    types:
    - uid: string
- name: H264RateControlMode
  description: The video rate control mode
  kind: enum
  properties:
  - name: ABR
    description: 'Average Bitrate (ABR) mode that hits the target bitrate: Default mode.'
    types:
    - uid: string
  - name: CBR
    description: Constant Bitrate (CBR) mode that tightens bitrate variations around target bitrate.
    types:
    - uid: string
  - name: CRF
    description: Constant Rate Factor (CRF) mode that targets at constant subjective quality.
    types:
    - uid: string
- name: JpgLayer
  description: Describes the settings to produce a JPEG image from the input video.
  kind: object
  properties:
  - name: quality
    description: The compression quality of the JPEG output. Range is from 0-100 and the default is 70.
    types:
    - uid: integer
  - name: width
    description: The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
    types:
    - uid: string
  - name: height
    description: The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
    types:
    - uid: string
  - name: label
    description: The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
    types:
    - uid: string
- name: PngLayer
  description: Describes the settings to produce a PNG image from the input video.
  kind: object
  properties:
  - name: width
    description: The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
    types:
    - uid: string
  - name: height
    description: The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
    types:
    - uid: string
  - name: label
    description: The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
    types:
    - uid: string
- name: AacAudioProfile
  description: The encoding profile to be used when encoding audio with AAC.
  kind: enum
  properties:
  - name: AacLc
    description: Specifies that the output audio is to be encoded into AAC Low Complexity profile (AAC-LC).
    types:
    - uid: string
  - name: HeAacV1
    description: Specifies that the output audio is to be encoded into HE-AAC v1 profile.
    types:
    - uid: string
  - name: HeAacV2
    description: Specifies that the output audio is to be encoded into HE-AAC v2 profile.
    types:
    - uid: string
- name: OutputFile
  description: Represents an output file produced.
  kind: object
  properties:
  - name: labels
    description: The list of labels that describe how the encoder should multiplex video and audio into an output file. For example, if the encoder is producing two video layers with labels v1 and v2, and one audio layer with label a1, then an array like '[v1, a1]' tells the encoder to produce an output file with the video track represented by v1 and the audio track represented by a1.
    types:
    - uid: string
      isArray: true
- name: H265VideoProfile
  description: We currently support Main. Default is Auto.
  kind: enum
  properties:
  - name: Auto
    description: Tells the encoder to automatically determine the appropriate H.265 profile.
    types:
    - uid: string
  - name: Main
    description: Main profile (https://x265.readthedocs.io/en/default/cli.html?highlight=profile#profile-level-tier)
    types:
    - uid: string
  - name: Main10
    description: Main 10 profile (https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding#Main_10)
    types:
    - uid: string
- name: H264VideoProfile
  description: We currently support Baseline, Main, High, High422, High444. Default is Auto.
  kind: enum
  properties:
  - name: Auto
    description: Tells the encoder to automatically determine the appropriate H.264 profile.
    types:
    - uid: string
  - name: Baseline
    description: Baseline profile
    types:
    - uid: string
  - name: Main
    description: Main profile
    types:
    - uid: string
  - name: High
    description: High profile.
    types:
    - uid: string
  - name: High422
    description: High 4:2:2 profile.
    types:
    - uid: string
  - name: High444
    description: High 4:4:4 predictive profile.
    types:
    - uid: string
- name: EntropyMode
  description: The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the profile and level.
  kind: enum
  properties:
  - name: Cabac
    description: Context Adaptive Binary Arithmetic Coder (CABAC) entropy encoding.
    types:
    - uid: string
  - name: Cavlc
    description: Context Adaptive Variable Length Coder (CAVLC) entropy encoding.
    types:
    - uid: string
examples:
- name: Get a Job by name
  request:
    uri: GET https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/contosoresources/providers/Microsoft.Media/mediaServices/contosomedia/transforms/exampleTransform/jobs/job1?api-version=2021-11-01
    codeTab: |+
      # [HTTP](#tab/HTTP)
      ``` http
      GET https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/contosoresources/providers/Microsoft.Media/mediaServices/contosomedia/transforms/exampleTransform/jobs/job1?api-version=2021-11-01
      ```

      # [Java](#tab/Java)
      ``` java
      import com.azure.core.util.Context;

      /** Samples for Jobs Get. */
      public final class Main {
          /*
           * x-ms-original-file: specification/mediaservices/resource-manager/Microsoft.Media/stable/2021-11-01/examples/jobs-get-by-name.json
           */
          /**
           * Sample code: Get a Job by name.
           *
           * @param manager Entry point to MediaServicesManager.
           */
          public static void getAJobByName(com.azure.resourcemanager.mediaservices.MediaServicesManager manager) {
              manager.jobs().getWithResponse("contosoresources", "contosomedia", "exampleTransform", "job1", Context.NONE);
          }
      }

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-java/blob/azure-resourcemanager-mediaservices_2.1.0/sdk/mediaservices/azure-resourcemanager-mediaservices/README.md) on how to add the SDK to your project and authenticate.
      # [Go](#tab/Go)
      ``` go
      package armmediaservices_test

      import (
      	"context"
      	"log"

      	"github.com/Azure/azure-sdk-for-go/sdk/azidentity"
      	"github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/mediaservices/armmediaservices/v3"
      )

      // Generated from example definition: https://github.com/Azure/azure-rest-api-specs/tree/main/specification/mediaservices/resource-manager/Microsoft.Media/stable/2021-11-01/examples/jobs-get-by-name.json
      func ExampleJobsClient_Get() {
      	cred, err := azidentity.NewDefaultAzureCredential(nil)
      	if err != nil {
      		log.Fatalf("failed to obtain a credential: %v", err)
      	}
      	ctx := context.Background()
      	client, err := armmediaservices.NewJobsClient("00000000-0000-0000-0000-000000000000", cred, nil)
      	if err != nil {
      		log.Fatalf("failed to create client: %v", err)
      	}
      	res, err := client.Get(ctx, "contosoresources", "contosomedia", "exampleTransform", "job1", nil)
      	if err != nil {
      		log.Fatalf("failed to finish the request: %v", err)
      	}
      	// TODO: use response item
      	_ = res
      }

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-go/blob/sdk%2Fresourcemanager%2Fmediaservices%2Farmmediaservices%2Fv3.1.0/sdk/resourcemanager/mediaservices/armmediaservices/README.md) on how to add the SDK to your project and authenticate.
      # [JavaScript](#tab/JavaScript)
      ``` js
      const { AzureMediaServices } = require("@azure/arm-mediaservices");
      const { DefaultAzureCredential } = require("@azure/identity");

      /**
       * This sample demonstrates how to Gets a Job.
       *
       * @summary Gets a Job.
       * x-ms-original-file: specification/mediaservices/resource-manager/Microsoft.Media/stable/2021-11-01/examples/jobs-get-by-name.json
       */
      async function getAJobByName() {
        const subscriptionId = "00000000-0000-0000-0000-000000000000";
        const resourceGroupName = "contosoresources";
        const accountName = "contosomedia";
        const transformName = "exampleTransform";
        const jobName = "job1";
        const credential = new DefaultAzureCredential();
        const client = new AzureMediaServices(credential, subscriptionId);
        const result = await client.jobs.get(resourceGroupName, accountName, transformName, jobName);
        console.log(result);
      }

      getAJobByName().catch(console.error);

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-js/blob/%40azure%2Farm-mediaservices_13.0.0/sdk/mediaservices/arm-mediaservices/README.md) on how to add the SDK to your project and authenticate.
  responses:
  - statusCode: "200"
    body: >-
      {
        "name": "job1",
        "id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/contosoresources/providers/Microsoft.Media/mediaservices/contosomedia/transforms/exampleTransform/jobs/job1",
        "type": "Microsoft.Media/mediaservices/transforms/jobs",
        "properties": {
          "created": "2021-11-01T00:00:00Z",
          "state": "Queued",
          "input": {
            "@odata.type": "#Microsoft.Media.JobInputs",
            "inputs": [
              {
                "@odata.type": "#Microsoft.Media.JobInputAsset",
                "files": [],
                "inputDefinitions": [],
                "assetName": "job1-InputAsset"
              }
            ]
          },
          "lastModified": "2021-11-01T00:00:00Z",
          "outputs": [
            {
              "@odata.type": "#Microsoft.Media.JobOutputAsset",
              "state": "Queued",
              "progress": 0,
              "label": "example-custom-label",
              "assetName": "job1-OutputAsset"
            }
          ],
          "priority": "Low",
          "correlationData": {}
        },
        "systemData": {
          "createdBy": "contoso@microsoft.com",
          "createdByType": "User",
          "createdAt": "2021-11-01T00:00:00Z",
          "lastModifiedBy": "contoso@microsoft.com",
          "lastModifiedByType": "User",
          "lastModifiedAt": "2021-11-01T00:00:00Z"
        }
      }
security: []
metadata:
  description: >
    Learn more about Media Services service - Get Job

    Gets a Job.
errorCodes: []
