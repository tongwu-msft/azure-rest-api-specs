### YamlMime:RESTOperation
uid: azureml.execution.startlocalrun
name: Start Local Run
service: Machine Learning
groupName: Execution
apiVersion: 2019-08-01
summary: "Start a run on a local machine.  \nStarts an experiment run using the provided definition.json file to define the run.\n            The source code and configuration is defined in a zip archive in project.zip."
consumes:
- application/json
produces:
- application/json
- application/octet-stream
paths:
- content: POST https:///execution/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/startlocalrun
- content: POST https:///execution/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/startlocalrun?runId={runId}
  isOptional: true
uriParameters:
- name: subscriptionId
  in: path
  isRequired: true
  description: The Azure Subscription ID.
  types:
  - uid: string
  format: uuid
- name: resourceGroupName
  in: path
  isRequired: true
  description: The Name of the resource group in which the workspace is located.
  types:
  - uid: string
- name: workspaceName
  in: path
  isRequired: true
  description: The name of the workspace.
  types:
  - uid: string
- name: experimentName
  in: path
  isRequired: true
  description: The experiment name.
  types:
  - uid: string
- name: runId
  in: query
  description: A run id. If not supplied a run id will be created automatically.
  types:
  - uid: string
  pattern: ^[a-zA-Z0-9][\w-]{0,255}$
responses:
- name: 200 OK
  description: File Response
  types:
  - uid: file
- name: Other Status Codes
  description: Error response describing why the operation failed.
  types:
  - uid: ErrorResponse
requestBody:
- name: default
  parameters:
  - name: configuration
    in: body
    description: >-
      Fully specified configuration information for the run. Even when that information

      is contained in configuration files within the project folder, the client collapses

      it all and inlines it into the run definition when submitting a run.
    types:
    - uid: RunConfiguration
  - name: snapshotId
    in: body
    description: >-
      Snapshots are user project folders that have been uploaded to the cloud for subsequent

      execution. This field is required when executing against cloud-based compute targets

      unless the run submission was against the API endpoint that takes a zipped project folder

      inline with the request.
    types:
    - uid: string
  - name: parentRunId
    in: body
    description: >-
      Specifies that the run history entry for this execution should be scoped within

      an existing run as a child. Defaults to null, meaning the run has no parent.

      This is intended for first-party service integration, not third-party API users.
    types:
    - uid: string
  - name: runType
    in: body
    description: Specifies the runsource property for this run. The default value is "experiment" if not specified.
    types:
    - uid: string
requestHeader: []
definitions:
- name: RunConfiguration
  kind: object
  properties:
  - name: script
    description: The relative path to the python script file. The file path is relative to the source_directory passed to submit run.
    types:
    - uid: string
  - name: arguments
    description: Command line arguments for the python script file.
    types:
    - uid: string
      isArray: true
  - name: framework
    description: The supported frameworks are Python, PySpark, CNTK, TensorFlow, and PyTorch. Use Tensorflow for AmlCompute clusters, and Python for distributed training jobs.
    types:
    - uid: Framework
  - name: communicator
    description: >-
      The supported communicators are None, ParameterServer, OpenMpi, and IntelMpi Keep in mind that OpenMpi requires a custom image with OpenMpi installed.

      Use ParameterServer or OpenMpi for AmlCompute clusters. Use IntelMpi for distributed training jobs.
    types:
    - uid: Communicator
  - name: target
    description: Target refers to compute where the job is scheduled for execution. The default target is "local" referring to the local machine.
    types:
    - uid: string
  - name: dataReferences
    description: All the data sources are made available to the run during execution based on each configuration.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: DataReferenceConfiguration
  - name: jobName
    description: >-
      This is primarily intended for notebooks to override the default job name.

      Defaults to ArgumentVector[0] if not specified.
    types:
    - uid: string
  - name: maxRunDurationSeconds
    description: >-
      Maximum allowed time for the run. The system will attempt to automatically cancel the run if it took longer than this value.

      MaxRunDurationSeconds=null means infinite duration.
    types:
    - uid: integer
  - name: nodeCount
    description: Number of compute nodes to run the job on. Only applies to AMLCompute.
    types:
    - uid: integer
  - name: environment
    description: >-
      The environment definition, This field configures the python environment.

      It can be configured to use an existing Python environment or configured to setup a temp environment for the experiment.

      The definition is also responsible for setting the required application dependencies.
    types:
    - uid: EnvironmentDefinition
  - name: history
    description: This section is used to disable and enable experiment history logging features.
    types:
    - uid: HistoryConfiguration
  - name: spark
    description: When the platform is set to Pyspark, The spark configuration is used to set the default sparkconf for the submitted job.
    types:
    - uid: SparkConfiguration
  - name: tensorflow
    description: >-
      The attribute is used to configure the distributed tensorflow parameters.

      This attribute takes effect only when the framework is set to TensorFlow, and the communicator to ParameterServer.

      AmlCompute is the only supported compute for this configuration.
    types:
    - uid: TensorflowConfiguration
  - name: mpi
    description: >-
      The attribute is used to configure the distributed MPI job parameters.

      This attribute takes effect only when the framework is set to Python, and the communicator to OpenMpi or IntelMpi.

      AmlCompute is the only supported compute type for this configuration.
    types:
    - uid: MpiConfiguration
  - name: hdi
    description: >-
      This attribute takes effect only when the target is set to an Azure HDI compute.

      The HDI Configuration is used to set the YARN deployment mode. It is defaulted to cluster mode.
    types:
    - uid: HdiConfiguration
- name: ErrorResponse
  description: The error response.
  kind: object
  properties:
  - name: error
    description: The top level error that occurred.
    types:
    - uid: RootError
  - name: correlation
    description: Dictionary containing correlation details for the error.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: environment
    description: The hosting environment.
    types:
    - uid: string
  - name: location
    description: The Azure region.
    types:
    - uid: string
  - name: time
    description: The time in UTC.
    types:
    - uid: string
- name: RunDefinition
  kind: object
  properties:
  - name: configuration
    description: >-
      Fully specified configuration information for the run. Even when that information

      is contained in configuration files within the project folder, the client collapses

      it all and inlines it into the run definition when submitting a run.
    types:
    - uid: RunConfiguration
  - name: snapshotId
    description: >-
      Snapshots are user project folders that have been uploaded to the cloud for subsequent

      execution. This field is required when executing against cloud-based compute targets

      unless the run submission was against the API endpoint that takes a zipped project folder

      inline with the request.
    types:
    - uid: string
  - name: parentRunId
    description: >-
      Specifies that the run history entry for this execution should be scoped within

      an existing run as a child. Defaults to null, meaning the run has no parent.

      This is intended for first-party service integration, not third-party API users.
    types:
    - uid: string
  - name: runType
    description: Specifies the runsource property for this run. The default value is "experiment" if not specified.
    types:
    - uid: string
- name: Framework
  description: The supported frameworks are Python, PySpark, CNTK, TensorFlow, and PyTorch. Use Tensorflow for AmlCompute clusters, and Python for distributed training jobs.
  kind: enum
  properties:
  - name: Python
    types:
    - uid: string
  - name: PySpark
    types:
    - uid: string
  - name: Cntk
    types:
    - uid: string
  - name: TensorFlow
    types:
    - uid: string
  - name: PyTorch
    types:
    - uid: string
- name: Communicator
  description: >-
    The supported communicators are None, ParameterServer, OpenMpi, and IntelMpi Keep in mind that OpenMpi requires a custom image with OpenMpi installed.

    Use ParameterServer or OpenMpi for AmlCompute clusters. Use IntelMpi for distributed training jobs.
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: ParameterServer
    types:
    - uid: string
  - name: Gloo
    types:
    - uid: string
  - name: Mpi
    types:
    - uid: string
  - name: Nccl
    types:
    - uid: string
- name: DataReferenceConfiguration
  description: A class for managing DataReferenceConfiguration.
  kind: object
  properties:
  - name: dataStoreName
    description: The name of the data store.
    types:
    - uid: string
  - name: mode
    description: Operation on the datastore, mount, download, upload.
    types:
    - uid: DataStoreMode
  - name: pathOnDataStore
    description: Relative path on the datastore.
    types:
    - uid: string
  - name: pathOnCompute
    description: The path on the compute target.
    types:
    - uid: string
  - name: overwrite
    description: Whether to overwrite the data if existing.
    types:
    - uid: boolean
- name: EnvironmentDefinition
  kind: object
  properties:
  - name: name
    description: The name of the environment.
    types:
    - uid: string
  - name: version
    description: The environment version.
    types:
    - uid: string
  - name: python
    description: Settings for a Python environment.
    types:
    - uid: PythonSection
  - name: environmentVariables
    description: Definition of environment variables to be defined in the environment.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: docker
    description: The definition of a Docker container.
    types:
    - uid: DockerSection
  - name: spark
    description: The configuration for a Spark environment.
    types:
    - uid: SparkSection
  - name: inferencingStackVersion
    description: 'The inferencing stack version added to the image. To avoid adding an inferencing stack, do not set this value. Valid values: "latest".'
    types:
    - uid: string
- name: HistoryConfiguration
  kind: object
  properties:
  - name: outputCollection
    description: Set to true to collect outputs and store in run history.
    types:
    - uid: boolean
  - name: directoriesToWatch
    description: The list of directories to monitor and upload files from.
    types:
    - uid: string
      isArray: true
- name: SparkConfiguration
  kind: object
  properties:
  - name: configuration
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
- name: TensorflowConfiguration
  kind: object
  properties:
  - name: workerCount
    description: The number of workers.
    types:
    - uid: integer
  - name: parameterServerCount
    description: Number of parameter servers.
    types:
    - uid: integer
- name: MpiConfiguration
  kind: object
  properties:
  - name: processCountPerNode
    description: Number of processes per node.
    types:
    - uid: integer
- name: HdiConfiguration
  kind: object
  properties:
  - name: yarnDeployMode
    description: ''
    types:
    - uid: YarnDeployMode
- name: RootError
  description: The root error.
  kind: object
  properties:
  - name: code
    description: 'The service-defined error code. Supported error codes: ServiceError, UserError, ValidationError, AzureStorageError, TransientError, RequestThrottled.'
    types:
    - uid: string
  - name: message
    description: A human-readable representation of the error.
    types:
    - uid: string
  - name: target
    description: The target of the error (e.g., the name of the property in error).
    types:
    - uid: string
  - name: details
    description: The related errors that occurred during the request.
    types:
    - uid: ErrorDetails
      isArray: true
  - name: innerError
    description: A nested list of inner errors. When evaluating errors, clients MUST traverse through all of the nested “innerErrors” and choose the deepest one that they understand.
    types:
    - uid: InnerErrorResponse
- name: DataStoreMode
  description: Operation on the datastore, mount, download, upload.
  kind: enum
  properties:
  - name: Mount
    types:
    - uid: string
  - name: Download
    types:
    - uid: string
  - name: Upload
    types:
    - uid: string
- name: PythonSection
  kind: object
  properties:
  - name: interpreterPath
    description: The python interpreter path. This is only used when user_managed_dependencies=True.
    types:
    - uid: string
  - name: userManagedDependencies
    description: True means that AzureML reuses an existing python environment; False means that AzureML will create a python environment based on the Conda dependencies specification.
    types:
    - uid: boolean
  - name: condaDependencies
    description: ''
    types:
    - uid: object
  - name: baseCondaEnvironment
    description: ''
    types:
    - uid: string
- name: DockerSection
  kind: object
  properties:
  - name: baseImage
    description: Base image used for Docker-based runs. Mutually exclusive with BaseDockerfile.
    types:
    - uid: string
  - name: baseDockerfile
    description: Base Dockerfile used for Docker-based runs. Mutually exclusive with BaseImage.
    types:
    - uid: string
  - name: enabled
    description: Set true to perform this run inside a Docker container.
    types:
    - uid: boolean
  - name: sharedVolumes
    description: Set false to disable AzureML's usage of the Docker shared volumes feature to work around bugs in certain versions of Docker for Windows.
    types:
    - uid: boolean
  - name: arguments
    description: Extra arguments to the Docker run command.
    types:
    - uid: string
      isArray: true
  - name: baseImageRegistry
    description: Image registry that contains the base image.
    types:
    - uid: ContainerRegistry
- name: SparkSection
  kind: object
  properties:
  - name: repositories
    description: The list of spark repositories.
    types:
    - uid: string
      isArray: true
  - name: packages
    description: The Spark packages to use.
    types:
    - uid: SparkMavenPackage
      isArray: true
  - name: precachePackages
    description: Whether to precache the packages.
    types:
    - uid: boolean
- name: YarnDeployMode
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: Client
    types:
    - uid: string
  - name: Cluster
    types:
    - uid: string
- name: ErrorDetails
  description: The error details.
  kind: object
  properties:
  - name: code
    description: The error code.
    types:
    - uid: string
  - name: message
    description: The error message.
    types:
    - uid: string
  - name: target
    description: The target of the error (e.g., the name of the property in error).
    types:
    - uid: string
- name: InnerErrorResponse
  description: A nested structure of errors.
  kind: object
  properties:
  - name: code
    description: The error code.
    types:
    - uid: string
  - name: innerError
    description: A nested list of inner errors. When evaluating errors, clients MUST traverse through all of the nested “innerErrors” and choose the deepest one that they understand.
    types:
    - uid: InnerErrorResponse
- name: ContainerRegistry
  kind: object
  properties:
  - name: address
    description: ''
    types:
    - uid: string
  - name: username
    description: ''
    types:
    - uid: string
  - name: password
    description: ''
    types:
    - uid: string
- name: SparkMavenPackage
  kind: object
  properties:
  - name: group
    description: ''
    types:
    - uid: string
  - name: artifact
    description: ''
    types:
    - uid: string
  - name: version
    description: ''
    types:
    - uid: string
examples:
- name: Start a local run
  request:
    uri: POST https:///execution/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/demo_resource_group/providers/Microsoft.MachineLearningServices/workspaces/demo_workspace/experiments/demo_experiment/startlocalrun
    body: >-
      {
        "snapshotId": "00000000-0000-0000-0000-000000000000",
        "configuration": {
          "script": "findsquare.py",
          "arguments": [
            "234"
          ],
          "framework": "Python",
          "communicator": "None",
          "target": "batchai",
          "maxRunDurationSeconds": 1200,
          "nodeCount": 1,
          "environment": {
            "python": {
              "interpreterPath": "python",
              "userManagedDependencies": false,
              "condaDependencies": {
                "name": "project_environment",
                "dependencies": [
                  "python=3.6.2",
                  {
                    "pip": [
                      "azureml-defaults"
                    ]
                  }
                ]
              }
            },
            "docker": {
              "baseImage": "mcr.microsoft.com/azureml/base:0.2.2"
            }
          },
          "history": {}
        }
      }
  responses:
  - statusCode: "200"
security:
- name: azure_auth
  type: oauth2
  flow: implicit
  authorizationUrl: https://login.microsoftonline.com/common/oauth2/authorize
  scopes:
  - name: user_impersonation
    description: impersonate your user account
errorCodes: []
