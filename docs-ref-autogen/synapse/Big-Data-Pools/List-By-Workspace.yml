### YamlMime:RESTOperation
uid: management.azure.com.synapse.bigdatapools.listbyworkspace
name: List By Workspace
service: Synapse
groupName: Big Data Pools
apiVersion: 2021-06-01-preview
summary: "List the Big Data pools in a workspace.  \nList Big Data pools in a workspace."
consumes: []
produces:
- application/json
paths:
- content: GET https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Synapse/workspaces/{workspaceName}/bigDataPools?api-version=2021-06-01-preview
uriParameters:
- name: subscriptionId
  in: path
  isRequired: true
  description: The ID of the target subscription.
  types:
  - uid: string
- name: resourceGroupName
  in: path
  isRequired: true
  description: The name of the resource group. The name is case insensitive.
  types:
  - uid: string
- name: workspaceName
  in: path
  isRequired: true
  description: The name of the workspace.
  types:
  - uid: string
- name: api-version
  in: query
  isRequired: true
  description: The API version to use for this operation.
  types:
  - uid: string
responses:
- name: 200 OK
  description: ''
  types:
  - uid: BigDataPoolResourceInfoListResult
- name: Other Status Codes
  description: ''
  types:
  - uid: ErrorResponse
requestHeader: []
definitions:
- name: BigDataPoolResourceInfoListResult
  description: Collection of Big Data pools
  kind: object
  properties:
  - name: nextLink
    description: Link to the next page of results
    types:
    - uid: string
  - name: value
    description: List of Big Data pools
    types:
    - uid: BigDataPoolResourceInfo
      isArray: true
- name: ErrorResponse
  description: Error response
  kind: object
  properties:
  - name: error
    description: The error object.
    types:
    - uid: ErrorDetail
- name: BigDataPoolResourceInfo
  description: Big Data pool
  kind: object
  properties:
  - name: properties.provisioningState
    description: The state of the Big Data pool.
    types:
    - uid: string
  - name: properties.autoScale
    description: "Spark pool auto-scaling properties  \nAuto-scaling properties"
    types:
    - uid: AutoScaleProperties
  - name: properties.creationDate
    isReadyOnly: true
    description: The time when the Big Data pool was created.
    types:
    - uid: string
  - name: properties.autoPause
    description: "Spark pool auto-pausing properties  \nAuto-pausing properties"
    types:
    - uid: AutoPauseProperties
  - name: properties.isComputeIsolationEnabled
    description: Whether compute isolation is required or not.
    types:
    - uid: boolean
  - name: properties.isAutotuneEnabled
    description: "Enable Autotune  \nWhether autotune is required or not."
    types:
    - uid: boolean
  - name: properties.sessionLevelPackagesEnabled
    description: Whether session level packages enabled.
    types:
    - uid: boolean
  - name: properties.cacheSize
    description: The cache size
    types:
    - uid: integer
  - name: properties.dynamicExecutorAllocation
    description: Dynamic Executor Allocation
    types:
    - uid: DynamicExecutorAllocation
  - name: properties.sparkEventsFolder
    description: The Spark events folder
    types:
    - uid: string
  - name: properties.nodeCount
    description: The number of nodes in the Big Data pool.
    types:
    - uid: integer
  - name: properties.libraryRequirements
    description: "Spark pool library version requirements  \nLibrary version requirements"
    types:
    - uid: LibraryRequirements
  - name: properties.customLibraries
    description: List of custom libraries/packages associated with the spark pool.
    types:
    - uid: LibraryInfo
      isArray: true
  - name: properties.sparkConfigProperties
    description: "Spark pool Config Properties  \nSpark configuration file to specify additional properties"
    types:
    - uid: SparkConfigProperties
  - name: properties.sparkVersion
    description: The Apache Spark version.
    types:
    - uid: string
  - name: properties.defaultSparkLogFolder
    description: The default folder where Spark logs will be written.
    types:
    - uid: string
  - name: properties.nodeSize
    description: The level of compute power that each node in the Big Data pool has.
    types:
    - uid: NodeSize
  - name: properties.nodeSizeFamily
    description: The kind of nodes that the Big Data pool provides.
    types:
    - uid: NodeSizeFamily
  - name: properties.lastSucceededTimestamp
    isReadyOnly: true
    description: The time when the Big Data pool was updated successfully.
    types:
    - uid: string
  - name: tags
    description: Resource tags.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: location
    description: The geo-location where the resource lives
    types:
    - uid: string
  - name: id
    isReadyOnly: true
    description: Fully qualified resource ID for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
    types:
    - uid: string
  - name: name
    isReadyOnly: true
    description: The name of the resource
    types:
    - uid: string
  - name: type
    isReadyOnly: true
    description: The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
    types:
    - uid: string
- name: ErrorDetail
  description: The error detail.
  kind: object
  properties:
  - name: code
    isReadyOnly: true
    description: The error code.
    types:
    - uid: string
  - name: message
    isReadyOnly: true
    description: The error message.
    types:
    - uid: string
  - name: target
    isReadyOnly: true
    description: The error target.
    types:
    - uid: string
  - name: details
    isReadyOnly: true
    description: The error details.
    types:
    - uid: ErrorDetail
      isArray: true
  - name: additionalInfo
    isReadyOnly: true
    description: The error additional info.
    types:
    - uid: ErrorAdditionalInfo
      isArray: true
- name: AutoScaleProperties
  description: Spark pool auto-scaling properties
  kind: object
  properties:
  - name: minNodeCount
    description: The minimum number of nodes the Big Data pool can support.
    types:
    - uid: integer
  - name: enabled
    description: Whether automatic scaling is enabled for the Big Data pool.
    types:
    - uid: boolean
  - name: maxNodeCount
    description: The maximum number of nodes the Big Data pool can support.
    types:
    - uid: integer
- name: AutoPauseProperties
  description: Spark pool auto-pausing properties
  kind: object
  properties:
  - name: delayInMinutes
    description: Number of minutes of idle time before the Big Data pool is automatically paused.
    types:
    - uid: integer
  - name: enabled
    description: Whether auto-pausing is enabled for the Big Data pool.
    types:
    - uid: boolean
- name: DynamicExecutorAllocation
  description: Dynamic Executor Allocation Properties
  kind: object
  properties:
  - name: enabled
    description: Indicates whether Dynamic Executor Allocation is enabled or not.
    types:
    - uid: boolean
  - name: minExecutors
    description: The minimum number of executors alloted
    types:
    - uid: integer
  - name: maxExecutors
    description: The maximum number of executors alloted
    types:
    - uid: integer
- name: LibraryRequirements
  description: Spark pool library version requirements
  kind: object
  properties:
  - name: time
    isReadyOnly: true
    description: The last update time of the library requirements file.
    types:
    - uid: string
  - name: content
    description: The library requirements.
    types:
    - uid: string
  - name: filename
    description: The filename of the library requirements file.
    types:
    - uid: string
- name: LibraryInfo
  description: Information about a library/package created at the workspace level.
  kind: object
  properties:
  - name: name
    description: Name of the library.
    types:
    - uid: string
  - name: path
    description: Storage blob path of library.
    types:
    - uid: string
  - name: containerName
    description: Storage blob container name.
    types:
    - uid: string
  - name: uploadedTimestamp
    description: The last update time of the library.
    types:
    - uid: string
  - name: type
    description: Type of the library.
    types:
    - uid: string
  - name: provisioningStatus
    isReadyOnly: true
    description: Provisioning status of the library/package.
    types:
    - uid: string
  - name: creatorId
    isReadyOnly: true
    description: Creator Id of the library/package.
    types:
    - uid: string
- name: SparkConfigProperties
  description: Spark pool Config Properties
  kind: object
  properties:
  - name: time
    isReadyOnly: true
    description: The last update time of the spark config properties file.
    types:
    - uid: string
  - name: content
    description: The spark config properties.
    types:
    - uid: string
  - name: filename
    description: The filename of the spark config properties file.
    types:
    - uid: string
  - name: configurationType
    description: The type of the spark config properties file.
    types:
    - uid: ConfigurationType
- name: NodeSize
  description: The level of compute power that each node in the Big Data pool has.
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: Small
    types:
    - uid: string
  - name: Medium
    types:
    - uid: string
  - name: Large
    types:
    - uid: string
  - name: XLarge
    types:
    - uid: string
  - name: XXLarge
    types:
    - uid: string
  - name: XXXLarge
    types:
    - uid: string
- name: NodeSizeFamily
  description: The kind of nodes that the Big Data pool provides.
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: MemoryOptimized
    types:
    - uid: string
  - name: HardwareAcceleratedFPGA
    types:
    - uid: string
  - name: HardwareAcceleratedGPU
    types:
    - uid: string
- name: ErrorAdditionalInfo
  description: The resource management error additional info.
  kind: object
  properties:
  - name: type
    isReadyOnly: true
    description: The additional info type.
    types:
    - uid: string
  - name: info
    isReadyOnly: true
    description: The additional info.
    types:
    - uid: object
- name: ConfigurationType
  description: The type of the spark config properties file.
  kind: enum
  properties:
  - name: File
    types:
    - uid: string
  - name: Artifact
    types:
    - uid: string
examples:
- name: List Big Data pools in a workspace
  request:
    uri: GET https://management.azure.com/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools?api-version=2021-06-01-preview
    codeTab: |+
      # [HTTP](#tab/HTTP)
      ``` http
      GET https://management.azure.com/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools?api-version=2021-06-01-preview
      ```

      # [Java](#tab/Java)
      ``` java
      import com.azure.core.util.Context;

      /** Samples for BigDataPools ListByWorkspace. */
      public final class Main {
          /*
           * x-ms-original-file: specification/synapse/resource-manager/Microsoft.Synapse/preview/2021-06-01-preview/examples/ListBigDataPoolsInWorkspace.json
           */
          /**
           * Sample code: List Big Data pools in a workspace.
           *
           * @param manager Entry point to SynapseManager.
           */
          public static void listBigDataPoolsInAWorkspace(com.azure.resourcemanager.synapse.SynapseManager manager) {
              manager.bigDataPools().listByWorkspace("ExampleResourceGroup", "ExampleWorkspace", Context.NONE);
          }
      }

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-java/blob/azure-resourcemanager-synapse_1.0.0-beta.6/sdk/synapse/azure-resourcemanager-synapse/README.md) on how to add the SDK to your project and authenticate.
      # [Go](#tab/Go)
      ``` go
      package armsynapse_test

      import (
      	"context"
      	"log"

      	"github.com/Azure/azure-sdk-for-go/sdk/azidentity"
      	"github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/synapse/armsynapse"
      )

      // Generated from example definition: https://github.com/Azure/azure-rest-api-specs/tree/main/specification/synapse/resource-manager/Microsoft.Synapse/preview/2021-06-01-preview/examples/ListBigDataPoolsInWorkspace.json
      func ExampleBigDataPoolsClient_NewListByWorkspacePager() {
      	cred, err := azidentity.NewDefaultAzureCredential(nil)
      	if err != nil {
      		log.Fatalf("failed to obtain a credential: %v", err)
      	}
      	ctx := context.Background()
      	client, err := armsynapse.NewBigDataPoolsClient("01234567-89ab-4def-0123-456789abcdef", cred, nil)
      	if err != nil {
      		log.Fatalf("failed to create client: %v", err)
      	}
      	pager := client.NewListByWorkspacePager("ExampleResourceGroup",
      		"ExampleWorkspace",
      		nil)
      	for pager.More() {
      		nextResult, err := pager.NextPage(ctx)
      		if err != nil {
      			log.Fatalf("failed to advance page: %v", err)
      		}
      		for _, v := range nextResult.Value {
      			// TODO: use page item
      			_ = v
      		}
      	}
      }

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-go/blob/sdk%2Fresourcemanager%2Fsynapse%2Farmsynapse%2Fv0.5.0/sdk/resourcemanager/synapse/armsynapse/README.md) on how to add the SDK to your project and authenticate.
      # [JavaScript](#tab/JavaScript)
      ``` js
      const { SynapseManagementClient } = require("@azure/arm-synapse");
      const { DefaultAzureCredential } = require("@azure/identity");

      /**
       * This sample demonstrates how to List Big Data pools in a workspace.
       *
       * @summary List Big Data pools in a workspace.
       * x-ms-original-file: specification/synapse/resource-manager/Microsoft.Synapse/preview/2021-06-01-preview/examples/ListBigDataPoolsInWorkspace.json
       */
      async function listBigDataPoolsInAWorkspace() {
        const subscriptionId = "01234567-89ab-4def-0123-456789abcdef";
        const resourceGroupName = "ExampleResourceGroup";
        const workspaceName = "ExampleWorkspace";
        const credential = new DefaultAzureCredential();
        const client = new SynapseManagementClient(credential, subscriptionId);
        const resArray = new Array();
        for await (let item of client.bigDataPools.listByWorkspace(resourceGroupName, workspaceName)) {
          resArray.push(item);
        }
        console.log(resArray);
      }

      listBigDataPoolsInAWorkspace().catch(console.error);

      ```
      Read this [SDK documentation](https://github.com/Azure/azure-sdk-for-js/blob/%40azure%2Farm-synapse_8.1.0-beta.1/sdk/synapse/arm-synapse/README.md) on how to add the SDK to your project and authenticate.
  responses:
  - statusCode: "200"
    body: >-
      {
        "value": [
          {
            "id": "/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools/ExamplePool",
            "type": "Microsoft.Synapse/workspaces/bigDataPools",
            "location": "West US 2",
            "name": "ExamplePool",
            "tags": {},
            "properties": {
              "provisioningState": "Succeeded",
              "sparkVersion": "2.4",
              "nodeCount": 4,
              "nodeSize": "Medium",
              "nodeSizeFamily": "MemoryOptimized",
              "autoScale": {
                "enabled": true,
                "minNodeCount": 3,
                "maxNodeCount": 50
              },
              "autoPause": {
                "enabled": true,
                "delayInMinutes": 15
              },
              "creationDate": "1970-01-01T00:00:00Z",
              "sparkEventsFolder": "/events",
              "libraryRequirements": {
                "time": "1970-01-01T00:00:00Z",
                "content": "",
                "filename": "requirements.txt"
              },
              "defaultSparkLogFolder": "/logs",
              "isAutotuneEnabled": false
            }
          },
          {
            "id": "/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools/ExamplePool2",
            "type": "Microsoft.Synapse/workspaces/bigDataPools",
            "location": "West US 2",
            "name": "ExamplePool2",
            "tags": {},
            "properties": {
              "provisioningState": "Succeeded",
              "sparkVersion": "2.4",
              "nodeCount": 4,
              "nodeSize": "Medium",
              "nodeSizeFamily": "MemoryOptimized",
              "autoScale": {
                "enabled": true,
                "minNodeCount": 3,
                "maxNodeCount": 50
              },
              "autoPause": {
                "enabled": true,
                "delayInMinutes": 15
              },
              "creationDate": "1970-01-01T00:00:00Z",
              "sparkEventsFolder": "/events",
              "libraryRequirements": {
                "time": "1970-01-01T00:00:00Z",
                "content": "",
                "filename": "requirements.txt"
              },
              "defaultSparkLogFolder": "/logs",
              "isAutotuneEnabled": false
            }
          }
        ],
        "nextLink": ""
      }
security: []
metadata:
  description: >
    Learn more about Synapse service - List the Big Data pools in a workspace.

    List Big Data pools in a workspace.
errorCodes: []
