### YamlMime:RESTOperation
uid: synapse.data-plane.sparkjobdefinition.createorupdatesparkjobdefinition
name: Create Or Update Spark Job Definition
service: Synapse
groupName: Spark Job Definition
apiVersion: 2020-12-01
summary: Creates or updates a Spark Job Definition.
consumes:
- application/json
produces:
- application/json
paths:
- content: PUT {endpoint}/sparkJobDefinitions/{sparkJobDefinitionName}?api-version=2020-12-01
uriParameters:
- name: endpoint
  in: path
  isRequired: true
  skipUrlEncoding: true
  description: The workspace development endpoint, for example https://myworkspace.dev.azuresynapse.net.
  types:
  - uid: string
- name: sparkJobDefinitionName
  in: path
  isRequired: true
  description: The spark job definition name.
  types:
  - uid: string
- name: api-version
  in: query
  isRequired: true
  description: The Synapse client API Version.
  types:
  - uid: string
responses:
- name: 200 OK
  description: OK.
  types:
  - uid: SparkJobDefinitionResource
- name: 202 Accepted
  description: Accepted.
- name: Other Status Codes
  description: An error response received from the Azure Synapse service.
  types:
  - uid: CloudError
requestBody:
- name: default
  parameters:
  - name: properties
    in: body
    isRequired: true
    description: Properties of spark job definition.
    types:
    - uid: SparkJobDefinition
requestHeader:
- name: If-Match
  in: header
  description: ETag of the Spark Job Definition entity.  Should only be specified for update, for which it should match existing entity or can be * for unconditional update.
  types:
  - uid: string
definitions:
- name: SparkJobDefinition
  description: Spark job definition.
  kind: object
  properties:
  - name: description
    description: The description of the Spark job definition.
    types:
    - uid: string
  - name: targetBigDataPool
    description: Big data pool reference.
    types:
    - uid: BigDataPoolReference
  - name: requiredSparkVersion
    description: The required Spark version of the application.
    types:
    - uid: string
  - name: language
    description: The language of the Spark application.
    types:
    - uid: string
  - name: jobProperties
    description: The properties of the Spark job.
    types:
    - uid: SparkJobProperties
  - name: folder
    description: The folder that this Spark job definition is in. If not specified, this Spark job definition will appear at the root level.
    types:
    - uid: Folder
- name: SparkJobDefinitionResource
  description: Spark job definition resource type.
  kind: object
  properties:
  - name: properties
    description: Properties of spark job definition.
    types:
    - uid: SparkJobDefinition
  - name: etag
    isReadyOnly: true
    description: Resource Etag.
    types:
    - uid: string
  - name: id
    isReadyOnly: true
    description: Fully qualified resource ID for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
    types:
    - uid: string
  - name: name
    isReadyOnly: true
    description: The name of the resource
    types:
    - uid: string
  - name: type
    isReadyOnly: true
    description: The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
    types:
    - uid: string
- name: CloudError
  description: The object that defines the structure of an Azure Synapse error response.
  kind: object
  properties:
  - name: error.code
    description: Error code.
    types:
    - uid: string
  - name: error.message
    description: Error message.
    types:
    - uid: string
  - name: error.target
    description: Property name/path in request associated with error.
    types:
    - uid: string
  - name: error.details
    description: Array with additional error details.
    types:
    - uid: CloudError
      isArray: true
- name: BigDataPoolReference
  description: Big data pool reference.
  kind: object
  properties:
  - name: type
    description: Big data pool reference type.
    types:
    - uid: BigDataPoolReferenceType
  - name: referenceName
    description: Reference big data pool name.
    types:
    - uid: string
- name: SparkJobProperties
  description: The properties of the Spark job.
  kind: object
  properties:
  - name: name
    description: The name of the job.
    types:
    - uid: string
  - name: file
    description: File containing the application to execute.
    types:
    - uid: string
  - name: className
    description: Main class for Java/Scala application.
    types:
    - uid: string
  - name: conf
    description: Spark configuration properties.
    types:
    - uid: object
  - name: args
    description: Command line arguments for the application.
    types:
    - uid: string
      isArray: true
  - name: jars
    description: Jars to be used in this job.
    types:
    - uid: string
      isArray: true
  - name: files
    description: files to be used in this job.
    types:
    - uid: string
      isArray: true
  - name: archives
    description: Archives to be used in this job.
    types:
    - uid: string
      isArray: true
  - name: driverMemory
    description: Amount of memory to use for the driver process.
    types:
    - uid: string
  - name: driverCores
    description: Number of cores to use for the driver.
    types:
    - uid: integer
  - name: executorMemory
    description: Amount of memory to use per executor process.
    types:
    - uid: string
  - name: executorCores
    description: Number of cores to use for each executor.
    types:
    - uid: integer
  - name: numExecutors
    description: Number of executors to launch for this job.
    types:
    - uid: integer
- name: Folder
  description: The folder that this Spark job definition is in. If not specified, this Spark job definition will appear at the root level.
  kind: object
  properties:
  - name: name
    description: The name of the folder that this Spark job definition is in.
    types:
    - uid: string
- name: BigDataPoolReferenceType
  description: Big data pool reference type.
  kind: enum
  properties:
  - name: BigDataPoolReference
    types:
    - uid: string
examples:
- name: SparkJobDefinitions_Create
  request:
    uri: PUT exampleWorkspace.dev.azuresynapse.net/sparkJobDefinitions/exampleSparkJobDefinition?api-version=2020-12-01
    body: >-
      {
        "properties": {
          "description": "A sample spark job definition",
          "targetBigDataPool": {
            "referenceName": "exampleBigDataPool",
            "type": "BigDataPoolReference"
          },
          "requiredSparkVersion": "2.4",
          "jobProperties": {
            "name": "exampleSparkJobDefinition",
            "file": "abfss://test@test.dfs.core.windows.net/artefacts/sample.jar",
            "className": "dev.test.tools.sample.Main",
            "conf": {},
            "args": [
              "exampleArg"
            ],
            "jars": [],
            "pyFiles": [],
            "files": [],
            "archives": [],
            "driverMemory": "28g",
            "driverCores": 4,
            "executorMemory": "28g",
            "executorCores": 4,
            "numExecutors": 2
          }
        }
      }
  responses:
  - statusCode: "202"
    headers:
    - name: Date
      value: Sat, 16 Jun 2019 00:37:38 GMT
    - name: X-Content-Type-Options
      value: nosniff
    - name: x-ms-ratelimit-remaining-subscription-writes
      value: "1194"
    - name: x-ms-request-id
      value: ce95d6dd-c04d-4b02-b7ad-fe79c9b26df0
    - name: x-ms-correlation-request-id
      value: ce95d6dd-c04d-4b02-b7ad-fe79c9b26df0
  - statusCode: "200"
    headers:
    - name: Date
      value: Sat, 16 Jun 2018 00:37:41 GMT
    - name: X-Content-Type-Options
      value: nosniff
    - name: x-ms-ratelimit-remaining-subscription-writes
      value: "1192"
    - name: x-ms-request-id
      value: e4c589b7-a9fe-4c28-981c-3855ec27d264
    - name: x-ms-correlation-request-id
      value: e4c589b7-a9fe-4c28-981c-3855ec27d264
    body: >-
      {
        "id": "/subscriptions/12345678-1234-1234-1234-12345678abc/resourceGroups/exampleResourceGroup/providers/Microsoft.Synapse/workspaces/exampleWorkspaceName/sparkjobdefinitions/exampleSparkJobDefinition",
        "name": "exampleSparkJobDefinition",
        "type": "Microsoft.Synapse/workspaces/sparkjobdefinitions",
        "properties": {
          "description": "A sample spark job definition",
          "targetBigDataPool": {
            "referenceName": "exampleBigDataPool",
            "type": "BigDataPoolReference"
          },
          "requiredSparkVersion": "2.4",
          "jobProperties": {
            "name": "exampleSparkJobDefinition",
            "file": "abfss://test@test.dfs.core.windows.net/artefacts/sample.jar",
            "className": "dev.test.tools.sample.Main",
            "conf": {},
            "args": [
              "exampleArg"
            ],
            "jars": [],
            "pyFiles": [],
            "files": [],
            "archives": [],
            "driverMemory": "28g",
            "driverCores": 4,
            "executorMemory": "28g",
            "executorCores": 4,
            "numExecutors": 2
          }
        },
        "etag": "0a0069d4-0000-0000-0000-5b245bd50000"
      }
- name: SparkJobDefinitions_Update
  request:
    uri: PUT exampleWorkspace.dev.azuresynapse.net/sparkJobDefinitions/exampleSparkJobDefinition?api-version=2020-12-01
    body: >-
      {
        "properties": {
          "description": "modified description",
          "targetBigDataPool": {
            "referenceName": "exampleBigDataPool",
            "type": "BigDataPoolReference"
          },
          "requiredSparkVersion": "2.4",
          "jobProperties": {
            "name": "exampleSparkJobDefinition",
            "file": "abfss://test@test.dfs.core.windows.net/artefacts/sample.jar",
            "className": "dev.test.tools.sample.Main",
            "conf": {},
            "args": [
              "exampleArg"
            ],
            "jars": [],
            "pyFiles": [],
            "files": [],
            "archives": [],
            "driverMemory": "28g",
            "driverCores": 4,
            "executorMemory": "28g",
            "executorCores": 4,
            "numExecutors": 2
          }
        }
      }
  responses:
  - statusCode: "202"
    headers:
    - name: Date
      value: Sat, 16 Jun 2019 00:37:38 GMT
    - name: X-Content-Type-Options
      value: nosniff
    - name: x-ms-ratelimit-remaining-subscription-writes
      value: "1194"
    - name: x-ms-request-id
      value: ce95d6dd-c04d-4b02-b7ad-fe79c9b26df0
    - name: x-ms-correlation-request-id
      value: ce95d6dd-c04d-4b02-b7ad-fe79c9b26df0
  - statusCode: "200"
    headers:
    - name: Date
      value: Sat, 16 Jun 2018 00:37:41 GMT
    - name: X-Content-Type-Options
      value: nosniff
    - name: x-ms-ratelimit-remaining-subscription-writes
      value: "1192"
    - name: x-ms-request-id
      value: e4c589b7-a9fe-4c28-981c-3855ec27d264
    - name: x-ms-correlation-request-id
      value: e4c589b7-a9fe-4c28-981c-3855ec27d264
    body: >-
      {
        "id": "/subscriptions/12345678-1234-1234-1234-12345678abc/resourceGroups/exampleResourceGroup/providers/Microsoft.Synapse/workspaces/exampleWorkspaceName/sparkjobdefinitions/exampleSparkJobDefinition",
        "name": "exampleSparkJobDefinition",
        "type": "Microsoft.Synapse/workspaces/sparkjobdefinitions",
        "properties": {
          "description": "modified description",
          "targetBigDataPool": {
            "referenceName": "exampleBigDataPool",
            "type": "BigDataPoolReference"
          },
          "requiredSparkVersion": "2.4",
          "jobProperties": {
            "name": "exampleSparkJobDefinition",
            "file": "abfss://test@test.dfs.core.windows.net/artefacts/sample.jar",
            "className": "dev.test.tools.sample.Main",
            "conf": {},
            "args": [
              "exampleArg"
            ],
            "jars": [],
            "pyFiles": [],
            "files": [],
            "archives": [],
            "driverMemory": "28g",
            "driverCores": 4,
            "executorMemory": "28g",
            "executorCores": 4,
            "numExecutors": 2
          }
        },
        "etag": "0a006cd4-0000-0000-0000-5b245bd60000"
      }
security: []
metadata:
  description: Learn more about Synapse service - Creates or updates a Spark Job Definition.
errorCodes: []
