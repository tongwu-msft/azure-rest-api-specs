### YamlMime:RESTOperation
uid: synapse.data-plane.sparkbatch.createsparkbatchjob
name: Create Spark Batch Job
service: Synapse
groupName: Spark Batch
apiVersion: 2020-12-01
summary: Create new spark batch job.
consumes:
- application/json
produces:
- application/json
paths:
- content: POST {endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches
- content: POST {endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches?detailed={detailed}
  isOptional: true
uriParameters:
- name: endpoint
  in: path
  isRequired: true
  skipUrlEncoding: true
  description: The workspace development endpoint, for example https://myworkspace.dev.azuresynapse.net.
  types:
  - uid: string
- name: livyApiVersion
  in: path
  isRequired: true
  skipUrlEncoding: true
  description: Valid api-version for the request.
  types:
  - uid: string
- name: sparkPoolName
  in: path
  isRequired: true
  skipUrlEncoding: true
  description: Name of the spark pool.
  types:
  - uid: string
- name: detailed
  in: query
  description: Optional query param specifying whether detailed response is returned beyond plain livy.
  types:
  - uid: boolean
responses:
- name: 200 OK
  description: Success
  types:
  - uid: SparkBatchJob
requestBody:
- name: default
  parameters:
  - name: tags
    in: body
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: artifactId
    in: body
    description: ''
    types:
    - uid: string
  - name: name
    in: body
    isRequired: true
    description: ''
    types:
    - uid: string
  - name: file
    in: body
    isRequired: true
    description: ''
    types:
    - uid: string
  - name: className
    in: body
    description: ''
    types:
    - uid: string
  - name: args
    in: body
    description: ''
    types:
    - uid: string
      isArray: true
  - name: jars
    in: body
    description: ''
    types:
    - uid: string
      isArray: true
  - name: pyFiles
    in: body
    description: ''
    types:
    - uid: string
      isArray: true
  - name: files
    in: body
    description: ''
    types:
    - uid: string
      isArray: true
  - name: archives
    in: body
    description: ''
    types:
    - uid: string
      isArray: true
  - name: conf
    in: body
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: driverMemory
    in: body
    description: ''
    types:
    - uid: string
  - name: driverCores
    in: body
    description: ''
    types:
    - uid: integer
  - name: executorMemory
    in: body
    description: ''
    types:
    - uid: string
  - name: executorCores
    in: body
    description: ''
    types:
    - uid: integer
  - name: numExecutors
    in: body
    description: ''
    types:
    - uid: integer
requestHeader: []
definitions:
- name: SparkBatchJob
  kind: object
  properties:
  - name: livyInfo
    description: ''
    types:
    - uid: SparkBatchJobState
  - name: name
    description: The batch name.
    types:
    - uid: string
  - name: workspaceName
    description: The workspace name.
    types:
    - uid: string
  - name: sparkPoolName
    description: The Spark pool name.
    types:
    - uid: string
  - name: submitterName
    description: The submitter name.
    types:
    - uid: string
  - name: submitterId
    description: The submitter identifier.
    types:
    - uid: string
  - name: artifactId
    description: The artifact identifier.
    types:
    - uid: string
  - name: jobType
    description: The job type.
    types:
    - uid: SparkJobType
  - name: result
    description: The Spark batch job result.
    types:
    - uid: SparkBatchJobResultType
  - name: schedulerInfo
    description: The scheduler information.
    types:
    - uid: SparkScheduler
  - name: pluginInfo
    description: The plugin information.
    types:
    - uid: SparkServicePlugin
  - name: errorInfo
    description: The error information.
    types:
    - uid: SparkServiceError
      isArray: true
  - name: tags
    description: The tags.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: id
    description: The session Id.
    types:
    - uid: integer
  - name: appId
    description: The application id of this session
    types:
    - uid: string
  - name: appInfo
    description: The detailed application info.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: state
    description: The batch state
    types:
    - uid: LivyStates
  - name: log
    description: The log lines.
    types:
    - uid: string
      isArray: true
- name: SparkBatchJobOptions
  kind: object
  properties:
  - name: tags
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: artifactId
    description: ''
    types:
    - uid: string
  - name: name
    description: ''
    types:
    - uid: string
  - name: file
    description: ''
    types:
    - uid: string
  - name: className
    description: ''
    types:
    - uid: string
  - name: args
    description: ''
    types:
    - uid: string
      isArray: true
  - name: jars
    description: ''
    types:
    - uid: string
      isArray: true
  - name: pyFiles
    description: ''
    types:
    - uid: string
      isArray: true
  - name: files
    description: ''
    types:
    - uid: string
      isArray: true
  - name: archives
    description: ''
    types:
    - uid: string
      isArray: true
  - name: conf
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: driverMemory
    description: ''
    types:
    - uid: string
  - name: driverCores
    description: ''
    types:
    - uid: integer
  - name: executorMemory
    description: ''
    types:
    - uid: string
  - name: executorCores
    description: ''
    types:
    - uid: integer
  - name: numExecutors
    description: ''
    types:
    - uid: integer
- name: SparkBatchJobState
  kind: object
  properties:
  - name: notStartedAt
    description: the time that at which "not_started" livy state was first seen.
    types:
    - uid: string
  - name: startingAt
    description: the time that at which "starting" livy state was first seen.
    types:
    - uid: string
  - name: runningAt
    description: the time that at which "running" livy state was first seen.
    types:
    - uid: string
  - name: deadAt
    description: time that at which "dead" livy state was first seen.
    types:
    - uid: string
  - name: successAt
    description: the time that at which "success" livy state was first seen.
    types:
    - uid: string
  - name: killedAt
    description: the time that at which "killed" livy state was first seen.
    types:
    - uid: string
  - name: recoveringAt
    description: the time that at which "recovering" livy state was first seen.
    types:
    - uid: string
  - name: currentState
    description: the Spark job state.
    types:
    - uid: string
  - name: jobCreationRequest
    description: ''
    types:
    - uid: SparkRequest
- name: SparkJobType
  description: The job type.
  kind: enum
  properties:
  - name: SparkBatch
    types:
    - uid: string
  - name: SparkSession
    types:
    - uid: string
- name: SparkBatchJobResultType
  description: The Spark batch job result.
  kind: enum
  properties:
  - name: Uncertain
    types:
    - uid: string
  - name: Succeeded
    types:
    - uid: string
  - name: Failed
    types:
    - uid: string
  - name: Cancelled
    types:
    - uid: string
- name: SparkScheduler
  kind: object
  properties:
  - name: submittedAt
    description: ''
    types:
    - uid: string
  - name: scheduledAt
    description: ''
    types:
    - uid: string
  - name: endedAt
    description: ''
    types:
    - uid: string
  - name: cancellationRequestedAt
    description: ''
    types:
    - uid: string
  - name: currentState
    description: ''
    types:
    - uid: SchedulerCurrentState
- name: SparkServicePlugin
  kind: object
  properties:
  - name: preparationStartedAt
    description: ''
    types:
    - uid: string
  - name: resourceAcquisitionStartedAt
    description: ''
    types:
    - uid: string
  - name: submissionStartedAt
    description: ''
    types:
    - uid: string
  - name: monitoringStartedAt
    description: ''
    types:
    - uid: string
  - name: cleanupStartedAt
    description: ''
    types:
    - uid: string
  - name: currentState
    description: ''
    types:
    - uid: PluginCurrentState
- name: SparkServiceError
  kind: object
  properties:
  - name: message
    description: ''
    types:
    - uid: string
  - name: errorCode
    description: ''
    types:
    - uid: string
  - name: source
    description: ''
    types:
    - uid: SparkErrorSource
- name: LivyStates
  description: The batch state
  kind: enum
  properties:
  - name: not_started
    types:
    - uid: string
  - name: starting
    types:
    - uid: string
  - name: idle
    types:
    - uid: string
  - name: busy
    types:
    - uid: string
  - name: shutting_down
    types:
    - uid: string
  - name: error
    types:
    - uid: string
  - name: dead
    types:
    - uid: string
  - name: killed
    types:
    - uid: string
  - name: success
    types:
    - uid: string
  - name: running
    types:
    - uid: string
  - name: recovering
    types:
    - uid: string
- name: SparkRequest
  kind: object
  properties:
  - name: name
    description: ''
    types:
    - uid: string
  - name: file
    description: ''
    types:
    - uid: string
  - name: className
    description: ''
    types:
    - uid: string
  - name: args
    description: ''
    types:
    - uid: string
      isArray: true
  - name: jars
    description: ''
    types:
    - uid: string
      isArray: true
  - name: pyFiles
    description: ''
    types:
    - uid: string
      isArray: true
  - name: files
    description: ''
    types:
    - uid: string
      isArray: true
  - name: archives
    description: ''
    types:
    - uid: string
      isArray: true
  - name: conf
    description: ''
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: driverMemory
    description: ''
    types:
    - uid: string
  - name: driverCores
    description: ''
    types:
    - uid: integer
  - name: executorMemory
    description: ''
    types:
    - uid: string
  - name: executorCores
    description: ''
    types:
    - uid: integer
  - name: numExecutors
    description: ''
    types:
    - uid: integer
- name: SchedulerCurrentState
  kind: enum
  properties:
  - name: Queued
    types:
    - uid: string
  - name: Scheduled
    types:
    - uid: string
  - name: Ended
    types:
    - uid: string
- name: PluginCurrentState
  kind: enum
  properties:
  - name: Preparation
    types:
    - uid: string
  - name: ResourceAcquisition
    types:
    - uid: string
  - name: Queued
    types:
    - uid: string
  - name: Submission
    types:
    - uid: string
  - name: Monitoring
    types:
    - uid: string
  - name: Cleanup
    types:
    - uid: string
  - name: Ended
    types:
    - uid: string
- name: SparkErrorSource
  kind: enum
  properties:
  - name: System
    types:
    - uid: string
  - name: User
    types:
    - uid: string
  - name: Unknown
    types:
    - uid: string
  - name: Dependency
    types:
    - uid: string
examples:
- name: Create new spark batch job.
  request:
    uri: POST myWorkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mySparkPool/batches?detailed=True
    body: >-
      {
        "tags": null,
        "artifactId": "fill in here",
        "name": "jobname",
        "file": "abfss://",
        "className": "classname",
        "args": [],
        "jars": [],
        "files": [],
        "archives": [],
        "conf": null,
        "driverMemory": "4g",
        "driverCores": 4,
        "executorMemory": "2g",
        "executorCores": 2,
        "numExecutors": 2
      }
    codeTab: |+
      # [HTTP](#tab/HTTP)
      ``` http
      POST myWorkspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/mySparkPool/batches?detailed=True

      {
        "tags": null,
        "artifactId": "fill in here",
        "name": "jobname",
        "file": "abfss://",
        "className": "classname",
        "args": [],
        "jars": [],
        "files": [],
        "archives": [],
        "conf": null,
        "driverMemory": "4g",
        "driverCores": 4,
        "executorMemory": "2g",
        "executorCores": 2,
        "numExecutors": 2
      }

      ```

  responses:
  - statusCode: "200"
    body: >-
      {
        "livyInfo": null,
        "name": "jobname",
        "workspaceName": "myWorkspace",
        "sparkPoolName": "mySparkPool",
        "submitterName": "thetime",
        "submitterId": "thesubmitterid",
        "artifactId": "fill in here",
        "jobType": "SparkBatch",
        "result": "Failed",
        "schedulerInfo": null,
        "pluginInfo": null,
        "errorInfo": [],
        "tags": null,
        "id": 1,
        "appId": "fill in here",
        "appInfo": null,
        "state": "the state",
        "log": []
      }
security: []
metadata:
  description: >
    Learn more about Synapse service - Create new spark batch job.
errorCodes: []
