### YamlMime:RESTOperation
uid: management.azure.com.synapse.bigdatapools.get
name: Get
service: Synapse
groupName: Big Data Pools
apiVersion: 2019-06-01-preview
summary: "Get Big Data pool  \nGet a Big Data pool."
consumes: []
produces:
- application/json
paths:
- content: GET https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Synapse/workspaces/{workspaceName}/bigDataPools/{bigDataPoolName}?api-version=2019-06-01-preview
uriParameters:
- name: subscriptionId
  in: path
  isRequired: true
  description: The ID of the target subscription.
  types:
  - uid: string
- name: resourceGroupName
  in: path
  isRequired: true
  description: The name of the resource group. The name is case insensitive.
  types:
  - uid: string
  pattern: ^[-\w\._\(\)]+$
- name: workspaceName
  in: path
  isRequired: true
  description: The name of the workspace
  types:
  - uid: string
- name: bigDataPoolName
  in: path
  isRequired: true
  description: Big Data pool name
  types:
  - uid: string
- name: api-version
  in: query
  isRequired: true
  description: The API version to use for this operation.
  types:
  - uid: string
responses:
- name: 200 OK
  description: ''
  types:
  - uid: BigDataPoolResourceInfo
- name: Other Status Codes
  description: ''
  types:
  - uid: ErrorContract
requestHeader: []
definitions:
- name: BigDataPoolResourceInfo
  description: Big Data pool
  kind: object
  properties:
  - name: properties.provisioningState
    description: The state of the Big Data pool.
    types:
    - uid: string
  - name: properties.autoScale
    description: "Spark pool auto-scaling properties  \nAuto-scaling properties"
    types:
    - uid: AutoScaleProperties
  - name: properties.creationDate
    description: The time when the Big Data pool was created.
    types:
    - uid: string
  - name: properties.autoPause
    description: "Spark pool auto-pausing properties  \nAuto-pausing properties"
    types:
    - uid: AutoPauseProperties
  - name: properties.sparkEventsFolder
    description: The Spark events folder
    types:
    - uid: string
  - name: properties.nodeCount
    description: The number of nodes in the Big Data pool.
    types:
    - uid: integer
  - name: properties.libraryRequirements
    description: "Spark pool library version requirements  \nLibrary version requirements"
    types:
    - uid: LibraryRequirements
  - name: properties.sparkVersion
    description: The Apache Spark version.
    types:
    - uid: string
  - name: properties.defaultSparkLogFolder
    description: The default folder where Spark logs will be written.
    types:
    - uid: string
  - name: properties.nodeSize
    description: The level of compute power that each node in the Big Data pool has.
    types:
    - uid: NodeSize
  - name: properties.nodeSizeFamily
    description: The kind of nodes that the Big Data pool provides.
    types:
    - uid: NodeSizeFamily
  - name: tags
    description: Resource tags.
    types:
    - uid: object
      isDictionary: true
      additionalTypes:
      - uid: string
      - uid: string
  - name: location
    description: The geo-location where the resource lives
    types:
    - uid: string
  - name: id
    isReadyOnly: true
    description: Fully qualified resource Id for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
    types:
    - uid: string
  - name: name
    isReadyOnly: true
    description: The name of the resource
    types:
    - uid: string
  - name: type
    isReadyOnly: true
    description: The type of the resource. Ex- Microsoft.Compute/virtualMachines or Microsoft.Storage/storageAccounts.
    types:
    - uid: string
- name: ErrorContract
  description: Error details.
  kind: object
  properties:
  - name: error
    description: The error details.
    types:
    - uid: ErrorResponse
- name: AutoScaleProperties
  description: Spark pool auto-scaling properties
  kind: object
  properties:
  - name: minNodeCount
    description: The minimum number of nodes the Big Data pool can support.
    types:
    - uid: integer
  - name: enabled
    description: Whether automatic scaling is enabled for the Big Data pool.
    types:
    - uid: boolean
  - name: maxNodeCount
    description: The maximum number of nodes the Big Data pool can support.
    types:
    - uid: integer
- name: AutoPauseProperties
  description: Spark pool auto-pausing properties
  kind: object
  properties:
  - name: delayInMinutes
    description: Number of minutes of idle time before the Big Data pool is automatically paused.
    types:
    - uid: integer
  - name: enabled
    description: Whether auto-pausing is enabled for the Big Data pool.
    types:
    - uid: boolean
- name: LibraryRequirements
  description: Spark pool library version requirements
  kind: object
  properties:
  - name: time
    isReadyOnly: true
    description: The last update time of the library requirements file.
    types:
    - uid: string
  - name: content
    description: The library requirements.
    types:
    - uid: string
  - name: filename
    description: The filename of the library requirements file.
    types:
    - uid: string
- name: NodeSize
  description: The level of compute power that each node in the Big Data pool has.
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: Small
    types:
    - uid: string
  - name: Medium
    types:
    - uid: string
  - name: Large
    types:
    - uid: string
- name: NodeSizeFamily
  description: The kind of nodes that the Big Data pool provides.
  kind: enum
  properties:
  - name: None
    types:
    - uid: string
  - name: MemoryOptimized
    types:
    - uid: string
- name: ErrorResponse
  description: The resource management error response.
  kind: object
  properties:
  - name: code
    isReadyOnly: true
    description: The error code.
    types:
    - uid: string
  - name: message
    isReadyOnly: true
    description: The error message.
    types:
    - uid: string
  - name: target
    isReadyOnly: true
    description: The error target.
    types:
    - uid: string
  - name: details
    isReadyOnly: true
    description: The error details.
    types:
    - uid: ErrorResponse
      isArray: true
  - name: additionalInfo
    isReadyOnly: true
    description: The error additional info.
    types:
    - uid: ErrorAdditionalInfo
      isArray: true
- name: ErrorAdditionalInfo
  description: The resource management error additional info.
  kind: object
  properties:
  - name: type
    isReadyOnly: true
    description: The additional info type.
    types:
    - uid: string
  - name: info
    isReadyOnly: true
    description: The additional info.
    types:
    - uid: object
examples:
- name: Get a Big Data pool
  request:
    uri: GET https://management.azure.com/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools/ExamplePool?api-version=2019-06-01-preview
  responses:
  - statusCode: "200"
    body: >-
      {
        "id": "/subscriptions/01234567-89ab-4def-0123-456789abcdef/resourceGroups/ExampleResourceGroup/providers/Microsoft.Synapse/workspaces/ExampleWorkspace/bigDataPools/ExamplePool",
        "type": "Microsoft.Synapse/workspaces/bigDataPools",
        "location": "West US 2",
        "name": "ExamplePool",
        "tags": {},
        "properties": {
          "provisioningState": "Succeeded",
          "sparkVersion": "2.4",
          "nodeCount": 4,
          "nodeSize": "Medium",
          "nodeSizeFamily": "MemoryOptimized",
          "autoScale": {
            "enabled": true,
            "minNodeCount": 3,
            "maxNodeCount": 50
          },
          "autoPause": {
            "enabled": true,
            "delayInMinutes": 15
          },
          "creationDate": "1970-01-01T00:00:00Z",
          "sparkEventsFolder": "/events",
          "libraryRequirements": {
            "time": "1970-01-01T00:00:00Z",
            "content": "",
            "filename": "requirements.txt"
          },
          "defaultSparkLogFolder": "/logs"
        }
      }
  - statusCode: default
    body: >-
      {
        "error": {
          "code": "Error code",
          "message": "Error message"
        }
      }
security: []
errorCodes: []
